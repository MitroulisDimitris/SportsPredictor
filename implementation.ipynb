{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0e7daea",
   "metadata": {},
   "source": [
    "### Catboost Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b84f4ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report\n",
    "\n",
    "\n",
    "class CatBoostMatchPredictor:\n",
    "    \"\"\"\n",
    "    A class for training, evaluating, and saving a CatBoost model\n",
    "    to predict match winners.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 feature_cols: list,\n",
    "                 target_col: str ,\n",
    "                 cat_features: list = None,\n",
    "                 params: dict = None,\n",
    "                 test_size: float = 0.2,\n",
    "                 random_state: int = 42):\n",
    "        self.feature_cols = feature_cols\n",
    "        self.target_col = target_col\n",
    "        self.cat_features = cat_features\n",
    "        self.test_size = test_size\n",
    "        self.random_state = random_state\n",
    "    \n",
    "        \n",
    "        # Default CatBoost parameters\n",
    "        if params is None:\n",
    "            params = {\n",
    "                'iterations': 1000,\n",
    "                'learning_rate': 0.05,\n",
    "                'depth': 6,\n",
    "                'eval_metric': 'AUC',\n",
    "                'random_seed': random_state,\n",
    "                'verbose': 100,\n",
    "                'early_stopping_rounds': 50\n",
    "            }\n",
    "        self.params = params\n",
    "        self.model = None\n",
    "        self.metrics = None\n",
    "        self.report = None\n",
    "\n",
    "    def fit(self, df: pd.DataFrame):\n",
    "        \"\"\"\n",
    "        Train the CatBoost model on the provided DataFrame.\n",
    "        \"\"\"\n",
    "        X = df[self.feature_cols].copy()  # Create a copy to avoid modifying the original DataFrame\n",
    "        y = df[self.target_col].copy()\n",
    "        \n",
    "        if self.cat_features:\n",
    "            for col in self.cat_features:\n",
    "                X[col] = X[col].astype(str)  # enforce string type\n",
    "        \n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y,\n",
    "            test_size=self.test_size,\n",
    "            random_state=self.random_state,\n",
    "            stratify=y\n",
    "        )\n",
    "        \n",
    "        \n",
    "        train_pool = Pool(data=X_train, label=y_train, cat_features=self.cat_features)\n",
    "        test_pool = Pool(data=X_test, label=y_test, cat_features=self.cat_features)\n",
    "\n",
    "        # Initialize and train the model\n",
    "        self.model = CatBoostClassifier(**self.params)\n",
    "        self.model.fit(train_pool, eval_set=test_pool)\n",
    "\n",
    "        # Predict and evaluate\n",
    "        y_pred = self.model.predict(X_test)\n",
    "        y_prob = self.model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        auc = roc_auc_score(y_test, y_prob)\n",
    "        report = classification_report(y_test, y_pred)\n",
    "\n",
    "        self.metrics = {'accuracy': accuracy, 'auc': auc}\n",
    "        self.report = report\n",
    "\n",
    "        print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"Test AUC: {auc:.4f}\")\n",
    "        print(\"Classification Report:\\n\", report)\n",
    "        return self\n",
    "\n",
    "    def evaluate(self, df: pd.DataFrame, verbose: bool = True) -> dict:\n",
    "        \"\"\"\n",
    "        Evaluate model performance on the given dataset.\n",
    "        \n",
    "        Args:\n",
    "            df: DataFrame containing both features and target\n",
    "            verbose: Whether to print metrics\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary containing accuracy, AUC, and classification report\n",
    "        \"\"\"\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"Model not trained yet. Call fit() first.\")\n",
    "\n",
    "        X = df[self.feature_cols].copy()\n",
    "        y = df[self.target_col].copy()\n",
    "\n",
    "        # Apply same preprocessing as in fit()\n",
    "        if self.cat_features:\n",
    "            for col in self.cat_features:\n",
    "                X[col] = X[col].fillna('missing').astype(str)\n",
    "\n",
    "        # Create evaluation pool\n",
    "        eval_pool = Pool(\n",
    "            data=X,\n",
    "            label=y,\n",
    "            cat_features=self.cat_features\n",
    "        )\n",
    "\n",
    "        # Generate predictions\n",
    "        y_pred = self.model.predict(eval_pool)\n",
    "        y_prob = self.model.predict_proba(eval_pool)[:, 1]\n",
    "\n",
    "        # Calculate metrics\n",
    "        metrics = {\n",
    "            'accuracy': accuracy_score(y, y_pred),\n",
    "            'auc': roc_auc_score(y, y_prob),\n",
    "            'report': classification_report(y, y_pred)\n",
    "        }\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Evaluation Accuracy: {metrics['accuracy']:.4f}\")\n",
    "            print(f\"Evaluation AUC: {metrics['auc']:.4f}\")\n",
    "            print(\"Classification Report:\\n\", metrics['report'])\n",
    "\n",
    "        return metrics\n",
    "    \n",
    "    def save_model(self, filepath: str):\n",
    "        \"\"\"\n",
    "        Save the trained model to a file.\n",
    "        \"\"\"\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"Model has not been trained yet. Call fit() before saving.\")\n",
    "        self.model.save_model(filepath)\n",
    "        print(f\"Model saved to {filepath}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054fb5f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.7319889\tbest: 0.7319889 (0)\ttotal: 155ms\tremaining: 3m 52s\n",
      "1:\ttest: 0.7366022\tbest: 0.7366022 (1)\ttotal: 302ms\tremaining: 3m 46s\n",
      "2:\ttest: 0.7394661\tbest: 0.7394661 (2)\ttotal: 461ms\tremaining: 3m 50s\n",
      "3:\ttest: 0.7401917\tbest: 0.7401917 (3)\ttotal: 617ms\tremaining: 3m 50s\n",
      "4:\ttest: 0.7408289\tbest: 0.7408289 (4)\ttotal: 765ms\tremaining: 3m 48s\n",
      "5:\ttest: 0.7410310\tbest: 0.7410310 (5)\ttotal: 924ms\tremaining: 3m 50s\n",
      "6:\ttest: 0.7419648\tbest: 0.7419648 (6)\ttotal: 1.09s\tremaining: 3m 52s\n",
      "7:\ttest: 0.7424372\tbest: 0.7424372 (7)\ttotal: 1.25s\tremaining: 3m 53s\n",
      "8:\ttest: 0.7427428\tbest: 0.7427428 (8)\ttotal: 1.4s\tremaining: 3m 51s\n",
      "9:\ttest: 0.7430960\tbest: 0.7430960 (9)\ttotal: 1.56s\tremaining: 3m 52s\n",
      "10:\ttest: 0.7433358\tbest: 0.7433358 (10)\ttotal: 1.7s\tremaining: 3m 50s\n",
      "11:\ttest: 0.7433980\tbest: 0.7433980 (11)\ttotal: 1.85s\tremaining: 3m 49s\n",
      "12:\ttest: 0.7437079\tbest: 0.7437079 (12)\ttotal: 2s\tremaining: 3m 48s\n",
      "13:\ttest: 0.7445074\tbest: 0.7445074 (13)\ttotal: 2.15s\tremaining: 3m 48s\n",
      "14:\ttest: 0.7445822\tbest: 0.7445822 (14)\ttotal: 2.34s\tremaining: 3m 51s\n",
      "15:\ttest: 0.7447660\tbest: 0.7447660 (15)\ttotal: 2.51s\tremaining: 3m 52s\n",
      "16:\ttest: 0.7454509\tbest: 0.7454509 (16)\ttotal: 2.66s\tremaining: 3m 51s\n",
      "17:\ttest: 0.7456103\tbest: 0.7456103 (17)\ttotal: 2.81s\tremaining: 3m 51s\n",
      "18:\ttest: 0.7458363\tbest: 0.7458363 (18)\ttotal: 2.95s\tremaining: 3m 50s\n",
      "19:\ttest: 0.7460051\tbest: 0.7460051 (19)\ttotal: 3.1s\tremaining: 3m 49s\n",
      "20:\ttest: 0.7461680\tbest: 0.7461680 (20)\ttotal: 3.25s\tremaining: 3m 48s\n",
      "21:\ttest: 0.7463117\tbest: 0.7463117 (21)\ttotal: 3.39s\tremaining: 3m 47s\n",
      "22:\ttest: 0.7464794\tbest: 0.7464794 (22)\ttotal: 3.52s\tremaining: 3m 46s\n",
      "23:\ttest: 0.7465516\tbest: 0.7465516 (23)\ttotal: 3.67s\tremaining: 3m 45s\n",
      "24:\ttest: 0.7465733\tbest: 0.7465733 (24)\ttotal: 3.74s\tremaining: 3m 40s\n",
      "25:\ttest: 0.7466431\tbest: 0.7466431 (25)\ttotal: 3.89s\tremaining: 3m 40s\n",
      "26:\ttest: 0.7466682\tbest: 0.7466682 (26)\ttotal: 4.05s\tremaining: 3m 40s\n",
      "27:\ttest: 0.7467891\tbest: 0.7467891 (27)\ttotal: 4.21s\tremaining: 3m 41s\n",
      "28:\ttest: 0.7467957\tbest: 0.7467957 (28)\ttotal: 4.35s\tremaining: 3m 40s\n",
      "29:\ttest: 0.7467958\tbest: 0.7467958 (29)\ttotal: 4.41s\tremaining: 3m 36s\n",
      "30:\ttest: 0.7469583\tbest: 0.7469583 (30)\ttotal: 4.56s\tremaining: 3m 36s\n",
      "31:\ttest: 0.7469753\tbest: 0.7469753 (31)\ttotal: 4.68s\tremaining: 3m 34s\n",
      "32:\ttest: 0.7470732\tbest: 0.7470732 (32)\ttotal: 4.82s\tremaining: 3m 34s\n",
      "33:\ttest: 0.7470968\tbest: 0.7470968 (33)\ttotal: 4.98s\tremaining: 3m 34s\n",
      "34:\ttest: 0.7471365\tbest: 0.7471365 (34)\ttotal: 5.12s\tremaining: 3m 34s\n",
      "35:\ttest: 0.7471816\tbest: 0.7471816 (35)\ttotal: 5.27s\tremaining: 3m 34s\n",
      "36:\ttest: 0.7472504\tbest: 0.7472504 (36)\ttotal: 5.41s\tremaining: 3m 33s\n",
      "37:\ttest: 0.7472786\tbest: 0.7472786 (37)\ttotal: 5.54s\tremaining: 3m 33s\n",
      "38:\ttest: 0.7473569\tbest: 0.7473569 (38)\ttotal: 5.69s\tremaining: 3m 33s\n",
      "39:\ttest: 0.7474250\tbest: 0.7474250 (39)\ttotal: 5.83s\tremaining: 3m 32s\n",
      "40:\ttest: 0.7475078\tbest: 0.7475078 (40)\ttotal: 5.99s\tremaining: 3m 33s\n",
      "41:\ttest: 0.7475926\tbest: 0.7475926 (41)\ttotal: 6.12s\tremaining: 3m 32s\n",
      "42:\ttest: 0.7475935\tbest: 0.7475935 (42)\ttotal: 6.23s\tremaining: 3m 31s\n",
      "43:\ttest: 0.7476060\tbest: 0.7476060 (43)\ttotal: 6.35s\tremaining: 3m 30s\n",
      "44:\ttest: 0.7476084\tbest: 0.7476084 (44)\ttotal: 6.42s\tremaining: 3m 27s\n",
      "45:\ttest: 0.7476302\tbest: 0.7476302 (45)\ttotal: 6.55s\tremaining: 3m 27s\n",
      "46:\ttest: 0.7476299\tbest: 0.7476302 (45)\ttotal: 6.63s\tremaining: 3m 25s\n",
      "47:\ttest: 0.7477410\tbest: 0.7477410 (47)\ttotal: 6.77s\tremaining: 3m 24s\n",
      "48:\ttest: 0.7478630\tbest: 0.7478630 (48)\ttotal: 6.91s\tremaining: 3m 24s\n",
      "49:\ttest: 0.7478673\tbest: 0.7478673 (49)\ttotal: 7.07s\tremaining: 3m 25s\n",
      "50:\ttest: 0.7479063\tbest: 0.7479063 (50)\ttotal: 7.28s\tremaining: 3m 26s\n",
      "51:\ttest: 0.7481523\tbest: 0.7481523 (51)\ttotal: 7.43s\tremaining: 3m 26s\n",
      "52:\ttest: 0.7481635\tbest: 0.7481635 (52)\ttotal: 7.52s\tremaining: 3m 25s\n",
      "53:\ttest: 0.7481594\tbest: 0.7481635 (52)\ttotal: 7.6s\tremaining: 3m 23s\n",
      "54:\ttest: 0.7481599\tbest: 0.7481635 (52)\ttotal: 7.73s\tremaining: 3m 23s\n",
      "55:\ttest: 0.7481573\tbest: 0.7481635 (52)\ttotal: 7.79s\tremaining: 3m 20s\n",
      "56:\ttest: 0.7481591\tbest: 0.7481635 (52)\ttotal: 7.95s\tremaining: 3m 21s\n",
      "57:\ttest: 0.7482119\tbest: 0.7482119 (57)\ttotal: 8.09s\tremaining: 3m 21s\n",
      "58:\ttest: 0.7482168\tbest: 0.7482168 (58)\ttotal: 8.24s\tremaining: 3m 21s\n",
      "59:\ttest: 0.7482178\tbest: 0.7482178 (59)\ttotal: 8.4s\tremaining: 3m 21s\n",
      "60:\ttest: 0.7482469\tbest: 0.7482469 (60)\ttotal: 8.53s\tremaining: 3m 21s\n",
      "61:\ttest: 0.7482743\tbest: 0.7482743 (61)\ttotal: 8.66s\tremaining: 3m 20s\n",
      "62:\ttest: 0.7483606\tbest: 0.7483606 (62)\ttotal: 8.78s\tremaining: 3m 20s\n",
      "63:\ttest: 0.7483677\tbest: 0.7483677 (63)\ttotal: 8.94s\tremaining: 3m 20s\n",
      "64:\ttest: 0.7484705\tbest: 0.7484705 (64)\ttotal: 9.07s\tremaining: 3m 20s\n",
      "65:\ttest: 0.7484931\tbest: 0.7484931 (65)\ttotal: 9.21s\tremaining: 3m 20s\n",
      "66:\ttest: 0.7484931\tbest: 0.7484931 (65)\ttotal: 9.31s\tremaining: 3m 19s\n",
      "67:\ttest: 0.7485093\tbest: 0.7485093 (67)\ttotal: 9.44s\tremaining: 3m 18s\n",
      "68:\ttest: 0.7485093\tbest: 0.7485093 (67)\ttotal: 9.48s\tremaining: 3m 16s\n",
      "69:\ttest: 0.7485249\tbest: 0.7485249 (69)\ttotal: 9.66s\tremaining: 3m 17s\n",
      "70:\ttest: 0.7485417\tbest: 0.7485417 (70)\ttotal: 9.79s\tremaining: 3m 17s\n",
      "71:\ttest: 0.7485535\tbest: 0.7485535 (71)\ttotal: 9.92s\tremaining: 3m 16s\n",
      "72:\ttest: 0.7485535\tbest: 0.7485535 (71)\ttotal: 9.99s\tremaining: 3m 15s\n",
      "73:\ttest: 0.7485535\tbest: 0.7485535 (73)\ttotal: 10.1s\tremaining: 3m 14s\n",
      "74:\ttest: 0.7485535\tbest: 0.7485535 (73)\ttotal: 10.1s\tremaining: 3m 12s\n",
      "75:\ttest: 0.7485526\tbest: 0.7485535 (73)\ttotal: 10.2s\tremaining: 3m 11s\n",
      "76:\ttest: 0.7485895\tbest: 0.7485895 (76)\ttotal: 10.3s\tremaining: 3m 11s\n",
      "77:\ttest: 0.7485873\tbest: 0.7485895 (76)\ttotal: 10.5s\tremaining: 3m 10s\n",
      "78:\ttest: 0.7486624\tbest: 0.7486624 (78)\ttotal: 10.6s\tremaining: 3m 10s\n",
      "79:\ttest: 0.7486838\tbest: 0.7486838 (79)\ttotal: 10.7s\tremaining: 3m 10s\n",
      "80:\ttest: 0.7486938\tbest: 0.7486938 (80)\ttotal: 10.9s\tremaining: 3m 10s\n",
      "81:\ttest: 0.7486931\tbest: 0.7486938 (80)\ttotal: 11s\tremaining: 3m 9s\n",
      "82:\ttest: 0.7486933\tbest: 0.7486938 (80)\ttotal: 11s\tremaining: 3m 8s\n",
      "83:\ttest: 0.7486933\tbest: 0.7486938 (80)\ttotal: 11.1s\tremaining: 3m 7s\n",
      "84:\ttest: 0.7487058\tbest: 0.7487058 (84)\ttotal: 11.2s\tremaining: 3m 6s\n",
      "85:\ttest: 0.7487077\tbest: 0.7487077 (85)\ttotal: 11.3s\tremaining: 3m 5s\n",
      "86:\ttest: 0.7487517\tbest: 0.7487517 (86)\ttotal: 11.4s\tremaining: 3m 5s\n",
      "87:\ttest: 0.7487641\tbest: 0.7487641 (87)\ttotal: 11.5s\tremaining: 3m 5s\n",
      "88:\ttest: 0.7487642\tbest: 0.7487642 (88)\ttotal: 11.6s\tremaining: 3m 4s\n",
      "89:\ttest: 0.7487648\tbest: 0.7487648 (89)\ttotal: 11.7s\tremaining: 3m 4s\n",
      "90:\ttest: 0.7487800\tbest: 0.7487800 (90)\ttotal: 11.9s\tremaining: 3m 3s\n",
      "91:\ttest: 0.7487881\tbest: 0.7487881 (91)\ttotal: 12s\tremaining: 3m 3s\n",
      "92:\ttest: 0.7487976\tbest: 0.7487976 (92)\ttotal: 12.1s\tremaining: 3m 3s\n",
      "93:\ttest: 0.7488290\tbest: 0.7488290 (93)\ttotal: 12.3s\tremaining: 3m 3s\n",
      "94:\ttest: 0.7488661\tbest: 0.7488661 (94)\ttotal: 12.4s\tremaining: 3m 3s\n",
      "95:\ttest: 0.7488919\tbest: 0.7488919 (95)\ttotal: 12.6s\tremaining: 3m 4s\n",
      "96:\ttest: 0.7488917\tbest: 0.7488919 (95)\ttotal: 12.7s\tremaining: 3m 3s\n",
      "97:\ttest: 0.7489018\tbest: 0.7489018 (97)\ttotal: 12.8s\tremaining: 3m 3s\n",
      "98:\ttest: 0.7488957\tbest: 0.7489018 (97)\ttotal: 12.9s\tremaining: 3m 3s\n",
      "99:\ttest: 0.7489649\tbest: 0.7489649 (99)\ttotal: 13.1s\tremaining: 3m 3s\n",
      "100:\ttest: 0.7490322\tbest: 0.7490322 (100)\ttotal: 13.2s\tremaining: 3m 3s\n",
      "101:\ttest: 0.7490818\tbest: 0.7490818 (101)\ttotal: 13.4s\tremaining: 3m 3s\n",
      "102:\ttest: 0.7492242\tbest: 0.7492242 (102)\ttotal: 13.5s\tremaining: 3m 3s\n",
      "103:\ttest: 0.7492285\tbest: 0.7492285 (103)\ttotal: 13.7s\tremaining: 3m 3s\n",
      "104:\ttest: 0.7492779\tbest: 0.7492779 (104)\ttotal: 13.8s\tremaining: 3m 3s\n",
      "105:\ttest: 0.7492849\tbest: 0.7492849 (105)\ttotal: 14s\tremaining: 3m 3s\n",
      "106:\ttest: 0.7494520\tbest: 0.7494520 (106)\ttotal: 14.1s\tremaining: 3m 3s\n",
      "107:\ttest: 0.7495476\tbest: 0.7495476 (107)\ttotal: 14.3s\tremaining: 3m 3s\n",
      "108:\ttest: 0.7496439\tbest: 0.7496439 (108)\ttotal: 14.4s\tremaining: 3m 3s\n",
      "109:\ttest: 0.7497027\tbest: 0.7497027 (109)\ttotal: 14.5s\tremaining: 3m 3s\n",
      "110:\ttest: 0.7496950\tbest: 0.7497027 (109)\ttotal: 14.7s\tremaining: 3m 3s\n",
      "111:\ttest: 0.7497237\tbest: 0.7497237 (111)\ttotal: 14.9s\tremaining: 3m 4s\n",
      "112:\ttest: 0.7497660\tbest: 0.7497660 (112)\ttotal: 15s\tremaining: 3m 4s\n",
      "113:\ttest: 0.7497785\tbest: 0.7497785 (113)\ttotal: 15.2s\tremaining: 3m 4s\n",
      "114:\ttest: 0.7498761\tbest: 0.7498761 (114)\ttotal: 15.3s\tremaining: 3m 4s\n",
      "115:\ttest: 0.7498986\tbest: 0.7498986 (115)\ttotal: 15.5s\tremaining: 3m 4s\n",
      "116:\ttest: 0.7499128\tbest: 0.7499128 (116)\ttotal: 15.6s\tremaining: 3m 4s\n",
      "117:\ttest: 0.7499210\tbest: 0.7499210 (117)\ttotal: 15.8s\tremaining: 3m 5s\n",
      "118:\ttest: 0.7499477\tbest: 0.7499477 (118)\ttotal: 15.9s\tremaining: 3m 5s\n",
      "119:\ttest: 0.7499461\tbest: 0.7499477 (118)\ttotal: 16.1s\tremaining: 3m 5s\n",
      "120:\ttest: 0.7499916\tbest: 0.7499916 (120)\ttotal: 16.3s\tremaining: 3m 5s\n",
      "121:\ttest: 0.7499913\tbest: 0.7499916 (120)\ttotal: 16.4s\tremaining: 3m 5s\n",
      "122:\ttest: 0.7499801\tbest: 0.7499916 (120)\ttotal: 16.6s\tremaining: 3m 5s\n",
      "123:\ttest: 0.7499817\tbest: 0.7499916 (120)\ttotal: 16.7s\tremaining: 3m 5s\n",
      "124:\ttest: 0.7499737\tbest: 0.7499916 (120)\ttotal: 16.9s\tremaining: 3m 5s\n",
      "125:\ttest: 0.7499978\tbest: 0.7499978 (125)\ttotal: 17s\tremaining: 3m 5s\n",
      "126:\ttest: 0.7499832\tbest: 0.7499978 (125)\ttotal: 17.2s\tremaining: 3m 5s\n",
      "127:\ttest: 0.7500041\tbest: 0.7500041 (127)\ttotal: 17.3s\tremaining: 3m 5s\n",
      "128:\ttest: 0.7500173\tbest: 0.7500173 (128)\ttotal: 17.5s\tremaining: 3m 5s\n",
      "129:\ttest: 0.7500101\tbest: 0.7500173 (128)\ttotal: 17.7s\tremaining: 3m 6s\n",
      "130:\ttest: 0.7500052\tbest: 0.7500173 (128)\ttotal: 17.8s\tremaining: 3m 6s\n",
      "131:\ttest: 0.7500299\tbest: 0.7500299 (131)\ttotal: 18s\tremaining: 3m 6s\n",
      "132:\ttest: 0.7500401\tbest: 0.7500401 (132)\ttotal: 18.1s\tremaining: 3m 6s\n",
      "133:\ttest: 0.7500327\tbest: 0.7500401 (132)\ttotal: 18.3s\tremaining: 3m 6s\n",
      "134:\ttest: 0.7500397\tbest: 0.7500401 (132)\ttotal: 18.4s\tremaining: 3m 6s\n",
      "135:\ttest: 0.7500421\tbest: 0.7500421 (135)\ttotal: 18.6s\tremaining: 3m 6s\n",
      "136:\ttest: 0.7500620\tbest: 0.7500620 (136)\ttotal: 18.7s\tremaining: 3m 6s\n",
      "137:\ttest: 0.7500661\tbest: 0.7500661 (137)\ttotal: 18.9s\tremaining: 3m 6s\n",
      "138:\ttest: 0.7500796\tbest: 0.7500796 (138)\ttotal: 19s\tremaining: 3m 6s\n",
      "139:\ttest: 0.7500780\tbest: 0.7500796 (138)\ttotal: 19.2s\tremaining: 3m 6s\n",
      "140:\ttest: 0.7500743\tbest: 0.7500796 (138)\ttotal: 19.4s\tremaining: 3m 6s\n",
      "141:\ttest: 0.7501176\tbest: 0.7501176 (141)\ttotal: 19.5s\tremaining: 3m 6s\n",
      "142:\ttest: 0.7501184\tbest: 0.7501184 (142)\ttotal: 19.7s\tremaining: 3m 6s\n",
      "143:\ttest: 0.7501094\tbest: 0.7501184 (142)\ttotal: 19.8s\tremaining: 3m 6s\n",
      "144:\ttest: 0.7501257\tbest: 0.7501257 (144)\ttotal: 20s\tremaining: 3m 6s\n",
      "145:\ttest: 0.7501315\tbest: 0.7501315 (145)\ttotal: 20.1s\tremaining: 3m 6s\n",
      "146:\ttest: 0.7501459\tbest: 0.7501459 (146)\ttotal: 20.3s\tremaining: 3m 6s\n",
      "147:\ttest: 0.7502104\tbest: 0.7502104 (147)\ttotal: 20.4s\tremaining: 3m 6s\n",
      "148:\ttest: 0.7502126\tbest: 0.7502126 (148)\ttotal: 20.6s\tremaining: 3m 6s\n",
      "149:\ttest: 0.7502328\tbest: 0.7502328 (149)\ttotal: 20.7s\tremaining: 3m 6s\n",
      "150:\ttest: 0.7502811\tbest: 0.7502811 (150)\ttotal: 20.9s\tremaining: 3m 6s\n",
      "151:\ttest: 0.7502925\tbest: 0.7502925 (151)\ttotal: 21s\tremaining: 3m 6s\n",
      "152:\ttest: 0.7503122\tbest: 0.7503122 (152)\ttotal: 21.2s\tremaining: 3m 6s\n",
      "153:\ttest: 0.7503837\tbest: 0.7503837 (153)\ttotal: 21.3s\tremaining: 3m 6s\n",
      "154:\ttest: 0.7503907\tbest: 0.7503907 (154)\ttotal: 21.5s\tremaining: 3m 6s\n",
      "155:\ttest: 0.7504283\tbest: 0.7504283 (155)\ttotal: 21.6s\tremaining: 3m 6s\n",
      "156:\ttest: 0.7504427\tbest: 0.7504427 (156)\ttotal: 21.8s\tremaining: 3m 6s\n",
      "157:\ttest: 0.7504461\tbest: 0.7504461 (157)\ttotal: 21.9s\tremaining: 3m 6s\n",
      "158:\ttest: 0.7504430\tbest: 0.7504461 (157)\ttotal: 22.1s\tremaining: 3m 6s\n",
      "159:\ttest: 0.7504542\tbest: 0.7504542 (159)\ttotal: 22.3s\tremaining: 3m 6s\n",
      "160:\ttest: 0.7504540\tbest: 0.7504542 (159)\ttotal: 22.4s\tremaining: 3m 6s\n",
      "161:\ttest: 0.7504719\tbest: 0.7504719 (161)\ttotal: 22.5s\tremaining: 3m 6s\n",
      "162:\ttest: 0.7504701\tbest: 0.7504719 (161)\ttotal: 22.6s\tremaining: 3m 5s\n",
      "163:\ttest: 0.7505113\tbest: 0.7505113 (163)\ttotal: 22.8s\tremaining: 3m 5s\n",
      "164:\ttest: 0.7505404\tbest: 0.7505404 (164)\ttotal: 22.9s\tremaining: 3m 5s\n",
      "165:\ttest: 0.7505426\tbest: 0.7505426 (165)\ttotal: 23.1s\tremaining: 3m 5s\n",
      "166:\ttest: 0.7505377\tbest: 0.7505426 (165)\ttotal: 23.3s\tremaining: 3m 5s\n",
      "167:\ttest: 0.7505359\tbest: 0.7505426 (165)\ttotal: 23.4s\tremaining: 3m 5s\n",
      "168:\ttest: 0.7505364\tbest: 0.7505426 (165)\ttotal: 23.6s\tremaining: 3m 5s\n",
      "169:\ttest: 0.7505349\tbest: 0.7505426 (165)\ttotal: 23.7s\tremaining: 3m 5s\n",
      "170:\ttest: 0.7505332\tbest: 0.7505426 (165)\ttotal: 23.9s\tremaining: 3m 5s\n",
      "171:\ttest: 0.7505426\tbest: 0.7505426 (171)\ttotal: 24s\tremaining: 3m 5s\n",
      "172:\ttest: 0.7505378\tbest: 0.7505426 (171)\ttotal: 24.2s\tremaining: 3m 5s\n",
      "173:\ttest: 0.7505709\tbest: 0.7505709 (173)\ttotal: 24.3s\tremaining: 3m 5s\n",
      "174:\ttest: 0.7505949\tbest: 0.7505949 (174)\ttotal: 24.5s\tremaining: 3m 5s\n",
      "175:\ttest: 0.7506125\tbest: 0.7506125 (175)\ttotal: 24.6s\tremaining: 3m 5s\n",
      "176:\ttest: 0.7506125\tbest: 0.7506125 (175)\ttotal: 24.7s\tremaining: 3m 4s\n",
      "177:\ttest: 0.7506160\tbest: 0.7506160 (177)\ttotal: 24.9s\tremaining: 3m 4s\n",
      "178:\ttest: 0.7506417\tbest: 0.7506417 (178)\ttotal: 25s\tremaining: 3m 4s\n",
      "179:\ttest: 0.7506606\tbest: 0.7506606 (179)\ttotal: 25.2s\tremaining: 3m 4s\n",
      "180:\ttest: 0.7506631\tbest: 0.7506631 (180)\ttotal: 25.3s\tremaining: 3m 4s\n",
      "181:\ttest: 0.7506606\tbest: 0.7506631 (180)\ttotal: 25.5s\tremaining: 3m 4s\n",
      "182:\ttest: 0.7506577\tbest: 0.7506631 (180)\ttotal: 25.7s\tremaining: 3m 4s\n",
      "183:\ttest: 0.7506630\tbest: 0.7506631 (180)\ttotal: 25.8s\tremaining: 3m 4s\n",
      "184:\ttest: 0.7506701\tbest: 0.7506701 (184)\ttotal: 26s\tremaining: 3m 4s\n",
      "185:\ttest: 0.7506837\tbest: 0.7506837 (185)\ttotal: 26.1s\tremaining: 3m 4s\n",
      "186:\ttest: 0.7506923\tbest: 0.7506923 (186)\ttotal: 26.3s\tremaining: 3m 4s\n",
      "187:\ttest: 0.7506911\tbest: 0.7506923 (186)\ttotal: 26.4s\tremaining: 3m 4s\n",
      "188:\ttest: 0.7506960\tbest: 0.7506960 (188)\ttotal: 26.6s\tremaining: 3m 4s\n",
      "189:\ttest: 0.7507004\tbest: 0.7507004 (189)\ttotal: 26.7s\tremaining: 3m 4s\n",
      "190:\ttest: 0.7506992\tbest: 0.7507004 (189)\ttotal: 26.9s\tremaining: 3m 4s\n",
      "191:\ttest: 0.7507381\tbest: 0.7507381 (191)\ttotal: 27s\tremaining: 3m 4s\n",
      "192:\ttest: 0.7507392\tbest: 0.7507392 (192)\ttotal: 27.2s\tremaining: 3m 4s\n",
      "193:\ttest: 0.7507830\tbest: 0.7507830 (193)\ttotal: 27.3s\tremaining: 3m 3s\n",
      "194:\ttest: 0.7507700\tbest: 0.7507830 (193)\ttotal: 27.5s\tremaining: 3m 3s\n",
      "195:\ttest: 0.7507864\tbest: 0.7507864 (195)\ttotal: 27.6s\tremaining: 3m 3s\n",
      "196:\ttest: 0.7507764\tbest: 0.7507864 (195)\ttotal: 27.8s\tremaining: 3m 3s\n",
      "197:\ttest: 0.7507719\tbest: 0.7507864 (195)\ttotal: 28s\tremaining: 3m 3s\n",
      "198:\ttest: 0.7507837\tbest: 0.7507864 (195)\ttotal: 28.1s\tremaining: 3m 3s\n",
      "199:\ttest: 0.7507995\tbest: 0.7507995 (199)\ttotal: 28.3s\tremaining: 3m 3s\n",
      "200:\ttest: 0.7508065\tbest: 0.7508065 (200)\ttotal: 28.4s\tremaining: 3m 3s\n",
      "201:\ttest: 0.7508067\tbest: 0.7508067 (201)\ttotal: 28.6s\tremaining: 3m 3s\n",
      "202:\ttest: 0.7508224\tbest: 0.7508224 (202)\ttotal: 28.7s\tremaining: 3m 3s\n",
      "203:\ttest: 0.7508267\tbest: 0.7508267 (203)\ttotal: 28.9s\tremaining: 3m 3s\n",
      "204:\ttest: 0.7508249\tbest: 0.7508267 (203)\ttotal: 29.1s\tremaining: 3m 3s\n",
      "205:\ttest: 0.7508239\tbest: 0.7508267 (203)\ttotal: 29.2s\tremaining: 3m 3s\n",
      "206:\ttest: 0.7508295\tbest: 0.7508295 (206)\ttotal: 29.4s\tremaining: 3m 3s\n",
      "207:\ttest: 0.7508424\tbest: 0.7508424 (207)\ttotal: 29.5s\tremaining: 3m 3s\n",
      "208:\ttest: 0.7508437\tbest: 0.7508437 (208)\ttotal: 29.7s\tremaining: 3m 3s\n",
      "209:\ttest: 0.7508421\tbest: 0.7508437 (208)\ttotal: 29.8s\tremaining: 3m 3s\n",
      "210:\ttest: 0.7508490\tbest: 0.7508490 (210)\ttotal: 30s\tremaining: 3m 3s\n",
      "211:\ttest: 0.7508501\tbest: 0.7508501 (211)\ttotal: 30.2s\tremaining: 3m 3s\n",
      "212:\ttest: 0.7508535\tbest: 0.7508535 (212)\ttotal: 30.3s\tremaining: 3m 3s\n",
      "213:\ttest: 0.7508516\tbest: 0.7508535 (212)\ttotal: 30.5s\tremaining: 3m 3s\n",
      "214:\ttest: 0.7508530\tbest: 0.7508535 (212)\ttotal: 30.6s\tremaining: 3m 3s\n",
      "215:\ttest: 0.7508423\tbest: 0.7508535 (212)\ttotal: 30.8s\tremaining: 3m 2s\n",
      "216:\ttest: 0.7508437\tbest: 0.7508535 (212)\ttotal: 30.9s\tremaining: 3m 2s\n",
      "217:\ttest: 0.7508461\tbest: 0.7508535 (212)\ttotal: 31.1s\tremaining: 3m 2s\n",
      "218:\ttest: 0.7508499\tbest: 0.7508535 (212)\ttotal: 31.2s\tremaining: 3m 2s\n",
      "219:\ttest: 0.7508661\tbest: 0.7508661 (219)\ttotal: 31.4s\tremaining: 3m 2s\n",
      "220:\ttest: 0.7508917\tbest: 0.7508917 (220)\ttotal: 31.6s\tremaining: 3m 2s\n",
      "221:\ttest: 0.7509110\tbest: 0.7509110 (221)\ttotal: 31.7s\tremaining: 3m 2s\n",
      "222:\ttest: 0.7509104\tbest: 0.7509110 (221)\ttotal: 31.9s\tremaining: 3m 2s\n",
      "223:\ttest: 0.7509051\tbest: 0.7509110 (221)\ttotal: 32.1s\tremaining: 3m 2s\n",
      "224:\ttest: 0.7509086\tbest: 0.7509110 (221)\ttotal: 32.2s\tremaining: 3m 2s\n",
      "225:\ttest: 0.7509135\tbest: 0.7509135 (225)\ttotal: 32.4s\tremaining: 3m 2s\n",
      "226:\ttest: 0.7509242\tbest: 0.7509242 (226)\ttotal: 32.5s\tremaining: 3m 2s\n",
      "227:\ttest: 0.7509254\tbest: 0.7509254 (227)\ttotal: 32.7s\tremaining: 3m 2s\n",
      "228:\ttest: 0.7509240\tbest: 0.7509254 (227)\ttotal: 32.8s\tremaining: 3m 2s\n",
      "229:\ttest: 0.7509251\tbest: 0.7509254 (227)\ttotal: 33s\tremaining: 3m 2s\n",
      "230:\ttest: 0.7509297\tbest: 0.7509297 (230)\ttotal: 33.1s\tremaining: 3m 2s\n",
      "231:\ttest: 0.7509324\tbest: 0.7509324 (231)\ttotal: 33.3s\tremaining: 3m 1s\n",
      "232:\ttest: 0.7509286\tbest: 0.7509324 (231)\ttotal: 33.5s\tremaining: 3m 2s\n",
      "233:\ttest: 0.7509323\tbest: 0.7509324 (231)\ttotal: 33.7s\tremaining: 3m 2s\n",
      "234:\ttest: 0.7509358\tbest: 0.7509358 (234)\ttotal: 33.8s\tremaining: 3m 2s\n",
      "235:\ttest: 0.7509416\tbest: 0.7509416 (235)\ttotal: 34s\tremaining: 3m 1s\n",
      "236:\ttest: 0.7509572\tbest: 0.7509572 (236)\ttotal: 34.1s\tremaining: 3m 1s\n",
      "237:\ttest: 0.7509680\tbest: 0.7509680 (237)\ttotal: 34.3s\tremaining: 3m 1s\n",
      "238:\ttest: 0.7509731\tbest: 0.7509731 (238)\ttotal: 34.4s\tremaining: 3m 1s\n",
      "239:\ttest: 0.7509731\tbest: 0.7509731 (239)\ttotal: 34.6s\tremaining: 3m 1s\n",
      "240:\ttest: 0.7509648\tbest: 0.7509731 (239)\ttotal: 34.7s\tremaining: 3m 1s\n",
      "241:\ttest: 0.7509673\tbest: 0.7509731 (239)\ttotal: 34.9s\tremaining: 3m 1s\n",
      "242:\ttest: 0.7509755\tbest: 0.7509755 (242)\ttotal: 35s\tremaining: 3m 1s\n",
      "243:\ttest: 0.7509834\tbest: 0.7509834 (243)\ttotal: 35.2s\tremaining: 3m 1s\n",
      "244:\ttest: 0.7509900\tbest: 0.7509900 (244)\ttotal: 35.3s\tremaining: 3m\n",
      "245:\ttest: 0.7510049\tbest: 0.7510049 (245)\ttotal: 35.5s\tremaining: 3m\n",
      "246:\ttest: 0.7510300\tbest: 0.7510300 (246)\ttotal: 35.6s\tremaining: 3m\n",
      "247:\ttest: 0.7510388\tbest: 0.7510388 (247)\ttotal: 35.8s\tremaining: 3m\n",
      "248:\ttest: 0.7510318\tbest: 0.7510388 (247)\ttotal: 36s\tremaining: 3m\n",
      "249:\ttest: 0.7510217\tbest: 0.7510388 (247)\ttotal: 36.1s\tremaining: 3m\n",
      "250:\ttest: 0.7510463\tbest: 0.7510463 (250)\ttotal: 36.3s\tremaining: 3m\n",
      "251:\ttest: 0.7510497\tbest: 0.7510497 (251)\ttotal: 36.4s\tremaining: 3m\n",
      "252:\ttest: 0.7510537\tbest: 0.7510537 (252)\ttotal: 36.6s\tremaining: 3m\n",
      "253:\ttest: 0.7510525\tbest: 0.7510537 (252)\ttotal: 36.7s\tremaining: 3m\n",
      "254:\ttest: 0.7510532\tbest: 0.7510537 (252)\ttotal: 36.9s\tremaining: 2m 59s\n",
      "255:\ttest: 0.7510651\tbest: 0.7510651 (255)\ttotal: 37s\tremaining: 2m 59s\n",
      "256:\ttest: 0.7510687\tbest: 0.7510687 (256)\ttotal: 37.2s\tremaining: 2m 59s\n",
      "257:\ttest: 0.7510698\tbest: 0.7510698 (257)\ttotal: 37.3s\tremaining: 2m 59s\n",
      "258:\ttest: 0.7510783\tbest: 0.7510783 (258)\ttotal: 37.5s\tremaining: 2m 59s\n",
      "259:\ttest: 0.7512035\tbest: 0.7512035 (259)\ttotal: 37.7s\tremaining: 2m 59s\n",
      "260:\ttest: 0.7512025\tbest: 0.7512035 (259)\ttotal: 37.9s\tremaining: 2m 59s\n",
      "261:\ttest: 0.7512007\tbest: 0.7512035 (259)\ttotal: 38s\tremaining: 2m 59s\n",
      "262:\ttest: 0.7511984\tbest: 0.7512035 (259)\ttotal: 38.2s\tremaining: 2m 59s\n",
      "263:\ttest: 0.7511966\tbest: 0.7512035 (259)\ttotal: 38.4s\tremaining: 2m 59s\n",
      "264:\ttest: 0.7512016\tbest: 0.7512035 (259)\ttotal: 38.5s\tremaining: 2m 59s\n",
      "265:\ttest: 0.7511962\tbest: 0.7512035 (259)\ttotal: 38.7s\tremaining: 2m 59s\n",
      "266:\ttest: 0.7511835\tbest: 0.7512035 (259)\ttotal: 38.9s\tremaining: 2m 59s\n",
      "267:\ttest: 0.7511894\tbest: 0.7512035 (259)\ttotal: 39s\tremaining: 2m 59s\n",
      "268:\ttest: 0.7511908\tbest: 0.7512035 (259)\ttotal: 39.2s\tremaining: 2m 59s\n",
      "269:\ttest: 0.7511865\tbest: 0.7512035 (259)\ttotal: 39.3s\tremaining: 2m 59s\n",
      "270:\ttest: 0.7511932\tbest: 0.7512035 (259)\ttotal: 39.5s\tremaining: 2m 58s\n",
      "271:\ttest: 0.7511873\tbest: 0.7512035 (259)\ttotal: 39.6s\tremaining: 2m 58s\n",
      "272:\ttest: 0.7511875\tbest: 0.7512035 (259)\ttotal: 39.9s\tremaining: 2m 59s\n",
      "273:\ttest: 0.7511876\tbest: 0.7512035 (259)\ttotal: 40s\tremaining: 2m 58s\n",
      "274:\ttest: 0.7512010\tbest: 0.7512035 (259)\ttotal: 40.1s\tremaining: 2m 58s\n",
      "275:\ttest: 0.7511952\tbest: 0.7512035 (259)\ttotal: 40.3s\tremaining: 2m 58s\n",
      "276:\ttest: 0.7511907\tbest: 0.7512035 (259)\ttotal: 40.4s\tremaining: 2m 58s\n",
      "277:\ttest: 0.7512208\tbest: 0.7512208 (277)\ttotal: 40.6s\tremaining: 2m 58s\n",
      "278:\ttest: 0.7512217\tbest: 0.7512217 (278)\ttotal: 40.7s\tremaining: 2m 58s\n",
      "279:\ttest: 0.7512450\tbest: 0.7512450 (279)\ttotal: 40.9s\tremaining: 2m 58s\n",
      "280:\ttest: 0.7512440\tbest: 0.7512450 (279)\ttotal: 41.1s\tremaining: 2m 58s\n",
      "281:\ttest: 0.7512438\tbest: 0.7512450 (279)\ttotal: 41.3s\tremaining: 2m 58s\n",
      "282:\ttest: 0.7512450\tbest: 0.7512450 (282)\ttotal: 41.4s\tremaining: 2m 57s\n",
      "283:\ttest: 0.7512486\tbest: 0.7512486 (283)\ttotal: 41.5s\tremaining: 2m 57s\n",
      "284:\ttest: 0.7512748\tbest: 0.7512748 (284)\ttotal: 41.7s\tremaining: 2m 57s\n",
      "285:\ttest: 0.7512755\tbest: 0.7512755 (285)\ttotal: 41.8s\tremaining: 2m 57s\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "import numpy as np\n",
    "\n",
    "long_df = pd.read_csv('long_df.csv')\n",
    "\n",
    "extra_cols = [\"winner_id\",\"loser_id\"]\n",
    "\n",
    "feature_cols = ['age_diff','ft_diff','elo_diff_pre','surface','winner_hand','loser_hand']\n",
    "\n",
    "cat_features = ['surface','winner_hand','loser_hand']\n",
    "\n",
    "#Train model\n",
    "params = {\n",
    "    'depth': 7, \n",
    "    'learning_rate': np.float64(0.13206014408119843), \n",
    "    'l2_leaf_reg': np.float64(1.961928922715895), \n",
    "    'bagging_temperature': np.float64(0.5692672525377181), \n",
    "    'subsample': np.float64(0.7335742829177031), \n",
    "    'min_data_in_leaf': 90, \n",
    "    'random_strength': np.float64(1.2000000000000002), \n",
    "    'iterations': 1500, \n",
    "    'eval_metric': 'AUC', \n",
    "    'early_stopping_rounds': 50, \n",
    "    'random_seed': 42\n",
    " }\n",
    "\n",
    "\n",
    "predictor = CatBoostMatchPredictor(\n",
    "    feature_cols=feature_cols,\n",
    "    target_col='label',\n",
    "    cat_features=cat_features,\n",
    "    params=params\n",
    ")\n",
    "\n",
    "predictor.fit(long_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f163658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712:\ttotal: 1m 59s\tremaining: 2m 11s\n",
      "713:\ttotal: 1m 59s\tremaining: 2m 11s\n",
      "714:\ttotal: 1m 59s\tremaining: 2m 11s\n",
      "715:\ttotal: 2m\tremaining: 2m 11s\n",
      "716:\ttotal: 2m\tremaining: 2m 11s\n",
      "717:\ttotal: 2m\tremaining: 2m 11s\n",
      "718:\ttotal: 2m\tremaining: 2m 10s\n",
      "719:\ttotal: 2m\tremaining: 2m 10s\n",
      "720:\ttotal: 2m\tremaining: 2m 10s\n",
      "721:\ttotal: 2m 1s\tremaining: 2m 10s\n",
      "722:\ttotal: 2m 1s\tremaining: 2m 10s\n",
      "723:\ttotal: 2m 1s\tremaining: 2m 10s\n",
      "724:\ttotal: 2m 1s\tremaining: 2m 10s\n",
      "725:\ttotal: 2m 1s\tremaining: 2m 9s\n",
      "726:\ttotal: 2m 1s\tremaining: 2m 9s\n",
      "727:\ttotal: 2m 2s\tremaining: 2m 9s\n",
      "728:\ttotal: 2m 2s\tremaining: 2m 9s\n",
      "729:\ttotal: 2m 2s\tremaining: 2m 9s\n",
      "730:\ttotal: 2m 2s\tremaining: 2m 9s\n",
      "731:\ttotal: 2m 2s\tremaining: 2m 8s\n",
      "732:\ttotal: 2m 2s\tremaining: 2m 8s\n",
      "733:\ttotal: 2m 3s\tremaining: 2m 8s\n",
      "734:\ttotal: 2m 3s\tremaining: 2m 8s\n",
      "735:\ttotal: 2m 3s\tremaining: 2m 8s\n",
      "736:\ttotal: 2m 3s\tremaining: 2m 7s\n",
      "737:\ttotal: 2m 3s\tremaining: 2m 7s\n",
      "738:\ttotal: 2m 3s\tremaining: 2m 7s\n",
      "739:\ttotal: 2m 4s\tremaining: 2m 7s\n",
      "740:\ttotal: 2m 4s\tremaining: 2m 7s\n",
      "741:\ttotal: 2m 4s\tremaining: 2m 7s\n",
      "742:\ttotal: 2m 4s\tremaining: 2m 6s\n",
      "743:\ttotal: 2m 4s\tremaining: 2m 6s\n",
      "744:\ttotal: 2m 4s\tremaining: 2m 6s\n",
      "745:\ttotal: 2m 5s\tremaining: 2m 6s\n",
      "746:\ttotal: 2m 5s\tremaining: 2m 6s\n",
      "747:\ttotal: 2m 5s\tremaining: 2m 6s\n",
      "748:\ttotal: 2m 5s\tremaining: 2m 5s\n",
      "749:\ttotal: 2m 5s\tremaining: 2m 5s\n",
      "750:\ttotal: 2m 5s\tremaining: 2m 5s\n",
      "751:\ttotal: 2m 6s\tremaining: 2m 5s\n",
      "752:\ttotal: 2m 6s\tremaining: 2m 5s\n",
      "753:\ttotal: 2m 6s\tremaining: 2m 5s\n",
      "754:\ttotal: 2m 6s\tremaining: 2m 4s\n",
      "755:\ttotal: 2m 6s\tremaining: 2m 4s\n",
      "756:\ttotal: 2m 6s\tremaining: 2m 4s\n",
      "757:\ttotal: 2m 7s\tremaining: 2m 4s\n",
      "758:\ttotal: 2m 7s\tremaining: 2m 4s\n",
      "759:\ttotal: 2m 7s\tremaining: 2m 4s\n",
      "760:\ttotal: 2m 7s\tremaining: 2m 3s\n",
      "761:\ttotal: 2m 7s\tremaining: 2m 3s\n",
      "762:\ttotal: 2m 7s\tremaining: 2m 3s\n",
      "763:\ttotal: 2m 8s\tremaining: 2m 3s\n",
      "764:\ttotal: 2m 8s\tremaining: 2m 3s\n",
      "765:\ttotal: 2m 8s\tremaining: 2m 2s\n",
      "766:\ttotal: 2m 8s\tremaining: 2m 2s\n",
      "767:\ttotal: 2m 8s\tremaining: 2m 2s\n",
      "768:\ttotal: 2m 8s\tremaining: 2m 2s\n",
      "769:\ttotal: 2m 9s\tremaining: 2m 2s\n",
      "770:\ttotal: 2m 9s\tremaining: 2m 2s\n",
      "771:\ttotal: 2m 9s\tremaining: 2m 2s\n",
      "772:\ttotal: 2m 9s\tremaining: 2m 1s\n",
      "773:\ttotal: 2m 9s\tremaining: 2m 1s\n",
      "774:\ttotal: 2m 9s\tremaining: 2m 1s\n",
      "775:\ttotal: 2m 10s\tremaining: 2m 1s\n",
      "776:\ttotal: 2m 10s\tremaining: 2m 1s\n",
      "777:\ttotal: 2m 10s\tremaining: 2m\n",
      "778:\ttotal: 2m 10s\tremaining: 2m\n",
      "779:\ttotal: 2m 10s\tremaining: 2m\n",
      "780:\ttotal: 2m 10s\tremaining: 2m\n",
      "781:\ttotal: 2m 11s\tremaining: 2m\n",
      "782:\ttotal: 2m 11s\tremaining: 2m\n",
      "783:\ttotal: 2m 11s\tremaining: 2m\n",
      "784:\ttotal: 2m 11s\tremaining: 1m 59s\n",
      "785:\ttotal: 2m 11s\tremaining: 1m 59s\n",
      "786:\ttotal: 2m 11s\tremaining: 1m 59s\n",
      "787:\ttotal: 2m 12s\tremaining: 1m 59s\n",
      "788:\ttotal: 2m 12s\tremaining: 1m 59s\n",
      "789:\ttotal: 2m 12s\tremaining: 1m 59s\n",
      "790:\ttotal: 2m 12s\tremaining: 1m 58s\n",
      "791:\ttotal: 2m 12s\tremaining: 1m 58s\n",
      "792:\ttotal: 2m 12s\tremaining: 1m 58s\n",
      "793:\ttotal: 2m 13s\tremaining: 1m 58s\n",
      "794:\ttotal: 2m 13s\tremaining: 1m 58s\n",
      "795:\ttotal: 2m 13s\tremaining: 1m 58s\n",
      "796:\ttotal: 2m 13s\tremaining: 1m 57s\n",
      "797:\ttotal: 2m 13s\tremaining: 1m 57s\n",
      "798:\ttotal: 2m 13s\tremaining: 1m 57s\n",
      "799:\ttotal: 2m 14s\tremaining: 1m 57s\n",
      "800:\ttotal: 2m 14s\tremaining: 1m 57s\n",
      "801:\ttotal: 2m 14s\tremaining: 1m 56s\n",
      "802:\ttotal: 2m 14s\tremaining: 1m 56s\n",
      "803:\ttotal: 2m 14s\tremaining: 1m 56s\n",
      "804:\ttotal: 2m 14s\tremaining: 1m 56s\n",
      "805:\ttotal: 2m 15s\tremaining: 1m 56s\n",
      "806:\ttotal: 2m 15s\tremaining: 1m 56s\n",
      "807:\ttotal: 2m 15s\tremaining: 1m 55s\n",
      "808:\ttotal: 2m 15s\tremaining: 1m 55s\n",
      "809:\ttotal: 2m 15s\tremaining: 1m 55s\n",
      "810:\ttotal: 2m 15s\tremaining: 1m 55s\n",
      "811:\ttotal: 2m 16s\tremaining: 1m 55s\n",
      "812:\ttotal: 2m 16s\tremaining: 1m 55s\n",
      "813:\ttotal: 2m 16s\tremaining: 1m 54s\n",
      "814:\ttotal: 2m 16s\tremaining: 1m 54s\n",
      "815:\ttotal: 2m 16s\tremaining: 1m 54s\n",
      "816:\ttotal: 2m 16s\tremaining: 1m 54s\n",
      "817:\ttotal: 2m 16s\tremaining: 1m 54s\n",
      "818:\ttotal: 2m 17s\tremaining: 1m 54s\n",
      "819:\ttotal: 2m 17s\tremaining: 1m 53s\n",
      "820:\ttotal: 2m 17s\tremaining: 1m 53s\n",
      "821:\ttotal: 2m 17s\tremaining: 1m 53s\n",
      "822:\ttotal: 2m 17s\tremaining: 1m 53s\n",
      "823:\ttotal: 2m 18s\tremaining: 1m 53s\n",
      "824:\ttotal: 2m 18s\tremaining: 1m 53s\n",
      "825:\ttotal: 2m 18s\tremaining: 1m 52s\n",
      "826:\ttotal: 2m 18s\tremaining: 1m 52s\n",
      "827:\ttotal: 2m 18s\tremaining: 1m 52s\n",
      "828:\ttotal: 2m 18s\tremaining: 1m 52s\n",
      "829:\ttotal: 2m 19s\tremaining: 1m 52s\n",
      "830:\ttotal: 2m 19s\tremaining: 1m 52s\n",
      "831:\ttotal: 2m 19s\tremaining: 1m 51s\n",
      "832:\ttotal: 2m 19s\tremaining: 1m 51s\n",
      "833:\ttotal: 2m 19s\tremaining: 1m 51s\n",
      "834:\ttotal: 2m 19s\tremaining: 1m 51s\n",
      "835:\ttotal: 2m 19s\tremaining: 1m 51s\n",
      "836:\ttotal: 2m 20s\tremaining: 1m 51s\n",
      "837:\ttotal: 2m 20s\tremaining: 1m 50s\n",
      "838:\ttotal: 2m 20s\tremaining: 1m 50s\n",
      "839:\ttotal: 2m 20s\tremaining: 1m 50s\n",
      "840:\ttotal: 2m 20s\tremaining: 1m 50s\n",
      "841:\ttotal: 2m 20s\tremaining: 1m 50s\n",
      "842:\ttotal: 2m 21s\tremaining: 1m 49s\n",
      "843:\ttotal: 2m 21s\tremaining: 1m 49s\n",
      "844:\ttotal: 2m 21s\tremaining: 1m 49s\n",
      "845:\ttotal: 2m 21s\tremaining: 1m 49s\n",
      "846:\ttotal: 2m 21s\tremaining: 1m 49s\n",
      "847:\ttotal: 2m 21s\tremaining: 1m 49s\n",
      "848:\ttotal: 2m 22s\tremaining: 1m 48s\n",
      "849:\ttotal: 2m 22s\tremaining: 1m 48s\n",
      "850:\ttotal: 2m 22s\tremaining: 1m 48s\n",
      "851:\ttotal: 2m 22s\tremaining: 1m 48s\n",
      "852:\ttotal: 2m 22s\tremaining: 1m 48s\n",
      "853:\ttotal: 2m 23s\tremaining: 1m 48s\n",
      "854:\ttotal: 2m 23s\tremaining: 1m 48s\n",
      "855:\ttotal: 2m 23s\tremaining: 1m 47s\n",
      "856:\ttotal: 2m 23s\tremaining: 1m 47s\n",
      "857:\ttotal: 2m 23s\tremaining: 1m 47s\n",
      "858:\ttotal: 2m 23s\tremaining: 1m 47s\n",
      "859:\ttotal: 2m 24s\tremaining: 1m 47s\n",
      "860:\ttotal: 2m 24s\tremaining: 1m 47s\n",
      "861:\ttotal: 2m 24s\tremaining: 1m 46s\n",
      "862:\ttotal: 2m 24s\tremaining: 1m 46s\n",
      "863:\ttotal: 2m 24s\tremaining: 1m 46s\n",
      "864:\ttotal: 2m 24s\tremaining: 1m 46s\n",
      "865:\ttotal: 2m 25s\tremaining: 1m 46s\n",
      "866:\ttotal: 2m 25s\tremaining: 1m 46s\n",
      "867:\ttotal: 2m 25s\tremaining: 1m 45s\n",
      "868:\ttotal: 2m 25s\tremaining: 1m 45s\n",
      "869:\ttotal: 2m 25s\tremaining: 1m 45s\n",
      "870:\ttotal: 2m 25s\tremaining: 1m 45s\n",
      "871:\ttotal: 2m 26s\tremaining: 1m 45s\n",
      "872:\ttotal: 2m 26s\tremaining: 1m 45s\n",
      "873:\ttotal: 2m 26s\tremaining: 1m 44s\n",
      "874:\ttotal: 2m 26s\tremaining: 1m 44s\n",
      "875:\ttotal: 2m 26s\tremaining: 1m 44s\n",
      "876:\ttotal: 2m 27s\tremaining: 1m 44s\n",
      "877:\ttotal: 2m 27s\tremaining: 1m 44s\n",
      "878:\ttotal: 2m 27s\tremaining: 1m 44s\n",
      "879:\ttotal: 2m 27s\tremaining: 1m 43s\n",
      "880:\ttotal: 2m 27s\tremaining: 1m 43s\n",
      "881:\ttotal: 2m 27s\tremaining: 1m 43s\n",
      "882:\ttotal: 2m 28s\tremaining: 1m 43s\n",
      "883:\ttotal: 2m 28s\tremaining: 1m 43s\n",
      "884:\ttotal: 2m 28s\tremaining: 1m 43s\n",
      "885:\ttotal: 2m 28s\tremaining: 1m 42s\n",
      "886:\ttotal: 2m 28s\tremaining: 1m 42s\n",
      "887:\ttotal: 2m 28s\tremaining: 1m 42s\n",
      "888:\ttotal: 2m 29s\tremaining: 1m 42s\n",
      "889:\ttotal: 2m 29s\tremaining: 1m 42s\n",
      "890:\ttotal: 2m 29s\tremaining: 1m 42s\n",
      "891:\ttotal: 2m 29s\tremaining: 1m 41s\n",
      "892:\ttotal: 2m 29s\tremaining: 1m 41s\n",
      "893:\ttotal: 2m 29s\tremaining: 1m 41s\n",
      "894:\ttotal: 2m 30s\tremaining: 1m 41s\n",
      "895:\ttotal: 2m 30s\tremaining: 1m 41s\n",
      "896:\ttotal: 2m 30s\tremaining: 1m 41s\n",
      "897:\ttotal: 2m 30s\tremaining: 1m 40s\n",
      "898:\ttotal: 2m 30s\tremaining: 1m 40s\n",
      "899:\ttotal: 2m 30s\tremaining: 1m 40s\n",
      "900:\ttotal: 2m 31s\tremaining: 1m 40s\n",
      "901:\ttotal: 2m 31s\tremaining: 1m 40s\n",
      "902:\ttotal: 2m 31s\tremaining: 1m 40s\n",
      "903:\ttotal: 2m 31s\tremaining: 1m 40s\n",
      "904:\ttotal: 2m 31s\tremaining: 1m 39s\n",
      "905:\ttotal: 2m 32s\tremaining: 1m 39s\n",
      "906:\ttotal: 2m 32s\tremaining: 1m 39s\n",
      "907:\ttotal: 2m 32s\tremaining: 1m 39s\n",
      "908:\ttotal: 2m 32s\tremaining: 1m 39s\n",
      "909:\ttotal: 2m 32s\tremaining: 1m 39s\n",
      "910:\ttotal: 2m 32s\tremaining: 1m 38s\n",
      "911:\ttotal: 2m 33s\tremaining: 1m 38s\n",
      "912:\ttotal: 2m 33s\tremaining: 1m 38s\n",
      "913:\ttotal: 2m 33s\tremaining: 1m 38s\n",
      "914:\ttotal: 2m 33s\tremaining: 1m 38s\n",
      "915:\ttotal: 2m 33s\tremaining: 1m 38s\n",
      "916:\ttotal: 2m 33s\tremaining: 1m 37s\n",
      "917:\ttotal: 2m 34s\tremaining: 1m 37s\n",
      "918:\ttotal: 2m 34s\tremaining: 1m 37s\n",
      "919:\ttotal: 2m 34s\tremaining: 1m 37s\n",
      "920:\ttotal: 2m 34s\tremaining: 1m 37s\n",
      "921:\ttotal: 2m 34s\tremaining: 1m 36s\n",
      "922:\ttotal: 2m 34s\tremaining: 1m 36s\n",
      "923:\ttotal: 2m 35s\tremaining: 1m 36s\n",
      "924:\ttotal: 2m 35s\tremaining: 1m 36s\n",
      "925:\ttotal: 2m 35s\tremaining: 1m 36s\n",
      "926:\ttotal: 2m 35s\tremaining: 1m 36s\n",
      "927:\ttotal: 2m 35s\tremaining: 1m 35s\n",
      "928:\ttotal: 2m 35s\tremaining: 1m 35s\n",
      "929:\ttotal: 2m 36s\tremaining: 1m 35s\n",
      "930:\ttotal: 2m 36s\tremaining: 1m 35s\n",
      "931:\ttotal: 2m 36s\tremaining: 1m 35s\n",
      "932:\ttotal: 2m 36s\tremaining: 1m 35s\n",
      "933:\ttotal: 2m 36s\tremaining: 1m 34s\n",
      "934:\ttotal: 2m 36s\tremaining: 1m 34s\n",
      "935:\ttotal: 2m 37s\tremaining: 1m 34s\n",
      "936:\ttotal: 2m 37s\tremaining: 1m 34s\n",
      "937:\ttotal: 2m 37s\tremaining: 1m 34s\n",
      "938:\ttotal: 2m 37s\tremaining: 1m 34s\n",
      "939:\ttotal: 2m 37s\tremaining: 1m 33s\n",
      "940:\ttotal: 2m 37s\tremaining: 1m 33s\n",
      "941:\ttotal: 2m 38s\tremaining: 1m 33s\n",
      "942:\ttotal: 2m 38s\tremaining: 1m 33s\n",
      "943:\ttotal: 2m 38s\tremaining: 1m 33s\n",
      "944:\ttotal: 2m 38s\tremaining: 1m 33s\n",
      "945:\ttotal: 2m 38s\tremaining: 1m 32s\n",
      "946:\ttotal: 2m 38s\tremaining: 1m 32s\n",
      "947:\ttotal: 2m 39s\tremaining: 1m 32s\n",
      "948:\ttotal: 2m 39s\tremaining: 1m 32s\n",
      "949:\ttotal: 2m 39s\tremaining: 1m 32s\n",
      "950:\ttotal: 2m 39s\tremaining: 1m 32s\n",
      "951:\ttotal: 2m 39s\tremaining: 1m 32s\n",
      "952:\ttotal: 2m 40s\tremaining: 1m 31s\n",
      "953:\ttotal: 2m 40s\tremaining: 1m 31s\n",
      "954:\ttotal: 2m 40s\tremaining: 1m 31s\n",
      "955:\ttotal: 2m 40s\tremaining: 1m 31s\n",
      "956:\ttotal: 2m 40s\tremaining: 1m 31s\n",
      "957:\ttotal: 2m 40s\tremaining: 1m 30s\n",
      "958:\ttotal: 2m 40s\tremaining: 1m 30s\n",
      "959:\ttotal: 2m 41s\tremaining: 1m 30s\n",
      "960:\ttotal: 2m 41s\tremaining: 1m 30s\n",
      "961:\ttotal: 2m 41s\tremaining: 1m 30s\n",
      "962:\ttotal: 2m 41s\tremaining: 1m 30s\n",
      "963:\ttotal: 2m 41s\tremaining: 1m 29s\n",
      "964:\ttotal: 2m 41s\tremaining: 1m 29s\n",
      "965:\ttotal: 2m 42s\tremaining: 1m 29s\n",
      "966:\ttotal: 2m 42s\tremaining: 1m 29s\n",
      "967:\ttotal: 2m 42s\tremaining: 1m 29s\n",
      "968:\ttotal: 2m 42s\tremaining: 1m 29s\n",
      "969:\ttotal: 2m 42s\tremaining: 1m 29s\n",
      "970:\ttotal: 2m 43s\tremaining: 1m 28s\n",
      "971:\ttotal: 2m 43s\tremaining: 1m 28s\n",
      "972:\ttotal: 2m 43s\tremaining: 1m 28s\n",
      "973:\ttotal: 2m 43s\tremaining: 1m 28s\n",
      "974:\ttotal: 2m 43s\tremaining: 1m 28s\n",
      "975:\ttotal: 2m 43s\tremaining: 1m 28s\n",
      "976:\ttotal: 2m 44s\tremaining: 1m 27s\n",
      "977:\ttotal: 2m 44s\tremaining: 1m 27s\n",
      "978:\ttotal: 2m 44s\tremaining: 1m 27s\n",
      "979:\ttotal: 2m 44s\tremaining: 1m 27s\n",
      "980:\ttotal: 2m 44s\tremaining: 1m 27s\n",
      "981:\ttotal: 2m 45s\tremaining: 1m 27s\n",
      "982:\ttotal: 2m 45s\tremaining: 1m 26s\n",
      "983:\ttotal: 2m 45s\tremaining: 1m 26s\n",
      "984:\ttotal: 2m 45s\tremaining: 1m 26s\n",
      "985:\ttotal: 2m 45s\tremaining: 1m 26s\n",
      "986:\ttotal: 2m 45s\tremaining: 1m 26s\n",
      "987:\ttotal: 2m 46s\tremaining: 1m 26s\n",
      "988:\ttotal: 2m 46s\tremaining: 1m 25s\n",
      "989:\ttotal: 2m 46s\tremaining: 1m 25s\n",
      "990:\ttotal: 2m 46s\tremaining: 1m 25s\n",
      "991:\ttotal: 2m 46s\tremaining: 1m 25s\n",
      "992:\ttotal: 2m 46s\tremaining: 1m 25s\n",
      "993:\ttotal: 2m 46s\tremaining: 1m 24s\n",
      "994:\ttotal: 2m 47s\tremaining: 1m 24s\n",
      "995:\ttotal: 2m 47s\tremaining: 1m 24s\n",
      "996:\ttotal: 2m 47s\tremaining: 1m 24s\n",
      "997:\ttotal: 2m 47s\tremaining: 1m 24s\n",
      "998:\ttotal: 2m 47s\tremaining: 1m 24s\n",
      "999:\ttotal: 2m 47s\tremaining: 1m 23s\n",
      "1000:\ttotal: 2m 48s\tremaining: 1m 23s\n",
      "1001:\ttotal: 2m 48s\tremaining: 1m 23s\n",
      "1002:\ttotal: 2m 48s\tremaining: 1m 23s\n",
      "1003:\ttotal: 2m 48s\tremaining: 1m 23s\n",
      "1004:\ttotal: 2m 48s\tremaining: 1m 23s\n",
      "1005:\ttotal: 2m 48s\tremaining: 1m 22s\n",
      "1006:\ttotal: 2m 49s\tremaining: 1m 22s\n",
      "1007:\ttotal: 2m 49s\tremaining: 1m 22s\n",
      "1008:\ttotal: 2m 49s\tremaining: 1m 22s\n",
      "1009:\ttotal: 2m 49s\tremaining: 1m 22s\n",
      "1010:\ttotal: 2m 49s\tremaining: 1m 22s\n",
      "1011:\ttotal: 2m 49s\tremaining: 1m 21s\n",
      "1012:\ttotal: 2m 50s\tremaining: 1m 21s\n",
      "1013:\ttotal: 2m 50s\tremaining: 1m 21s\n",
      "1014:\ttotal: 2m 50s\tremaining: 1m 21s\n",
      "1015:\ttotal: 2m 50s\tremaining: 1m 21s\n",
      "1016:\ttotal: 2m 50s\tremaining: 1m 21s\n",
      "1017:\ttotal: 2m 50s\tremaining: 1m 20s\n",
      "1018:\ttotal: 2m 51s\tremaining: 1m 20s\n",
      "1019:\ttotal: 2m 51s\tremaining: 1m 20s\n",
      "1020:\ttotal: 2m 51s\tremaining: 1m 20s\n",
      "1021:\ttotal: 2m 51s\tremaining: 1m 20s\n",
      "1022:\ttotal: 2m 51s\tremaining: 1m 20s\n",
      "1023:\ttotal: 2m 51s\tremaining: 1m 19s\n",
      "1024:\ttotal: 2m 52s\tremaining: 1m 19s\n",
      "1025:\ttotal: 2m 52s\tremaining: 1m 19s\n",
      "1026:\ttotal: 2m 52s\tremaining: 1m 19s\n",
      "1027:\ttotal: 2m 52s\tremaining: 1m 19s\n",
      "1028:\ttotal: 2m 52s\tremaining: 1m 19s\n",
      "1029:\ttotal: 2m 52s\tremaining: 1m 18s\n",
      "1030:\ttotal: 2m 53s\tremaining: 1m 18s\n",
      "1031:\ttotal: 2m 53s\tremaining: 1m 18s\n",
      "1032:\ttotal: 2m 53s\tremaining: 1m 18s\n",
      "1033:\ttotal: 2m 53s\tremaining: 1m 18s\n",
      "1034:\ttotal: 2m 53s\tremaining: 1m 18s\n",
      "1035:\ttotal: 2m 53s\tremaining: 1m 17s\n",
      "1036:\ttotal: 2m 54s\tremaining: 1m 17s\n",
      "1037:\ttotal: 2m 54s\tremaining: 1m 17s\n",
      "1038:\ttotal: 2m 54s\tremaining: 1m 17s\n",
      "1039:\ttotal: 2m 54s\tremaining: 1m 17s\n",
      "1040:\ttotal: 2m 54s\tremaining: 1m 17s\n",
      "1041:\ttotal: 2m 54s\tremaining: 1m 16s\n",
      "1042:\ttotal: 2m 55s\tremaining: 1m 16s\n",
      "1043:\ttotal: 2m 55s\tremaining: 1m 16s\n",
      "1044:\ttotal: 2m 55s\tremaining: 1m 16s\n",
      "1045:\ttotal: 2m 55s\tremaining: 1m 16s\n",
      "1046:\ttotal: 2m 55s\tremaining: 1m 16s\n",
      "1047:\ttotal: 2m 55s\tremaining: 1m 15s\n",
      "1048:\ttotal: 2m 56s\tremaining: 1m 15s\n",
      "1049:\ttotal: 2m 56s\tremaining: 1m 15s\n",
      "1050:\ttotal: 2m 56s\tremaining: 1m 15s\n",
      "1051:\ttotal: 2m 56s\tremaining: 1m 15s\n",
      "1052:\ttotal: 2m 56s\tremaining: 1m 14s\n",
      "1053:\ttotal: 2m 56s\tremaining: 1m 14s\n",
      "1054:\ttotal: 2m 56s\tremaining: 1m 14s\n",
      "1055:\ttotal: 2m 57s\tremaining: 1m 14s\n",
      "1056:\ttotal: 2m 57s\tremaining: 1m 14s\n",
      "1057:\ttotal: 2m 57s\tremaining: 1m 14s\n",
      "1058:\ttotal: 2m 57s\tremaining: 1m 13s\n",
      "1059:\ttotal: 2m 57s\tremaining: 1m 13s\n",
      "1060:\ttotal: 2m 58s\tremaining: 1m 13s\n",
      "1061:\ttotal: 2m 58s\tremaining: 1m 13s\n",
      "1062:\ttotal: 2m 58s\tremaining: 1m 13s\n",
      "1063:\ttotal: 2m 58s\tremaining: 1m 13s\n",
      "1064:\ttotal: 2m 58s\tremaining: 1m 12s\n",
      "1065:\ttotal: 2m 58s\tremaining: 1m 12s\n",
      "1066:\ttotal: 2m 59s\tremaining: 1m 12s\n",
      "1067:\ttotal: 2m 59s\tremaining: 1m 12s\n",
      "1068:\ttotal: 2m 59s\tremaining: 1m 12s\n",
      "1069:\ttotal: 2m 59s\tremaining: 1m 12s\n",
      "1070:\ttotal: 2m 59s\tremaining: 1m 11s\n",
      "1071:\ttotal: 2m 59s\tremaining: 1m 11s\n",
      "1072:\ttotal: 3m\tremaining: 1m 11s\n",
      "1073:\ttotal: 3m\tremaining: 1m 11s\n",
      "1074:\ttotal: 3m\tremaining: 1m 11s\n",
      "1075:\ttotal: 3m\tremaining: 1m 11s\n",
      "1076:\ttotal: 3m\tremaining: 1m 10s\n",
      "1077:\ttotal: 3m\tremaining: 1m 10s\n",
      "1078:\ttotal: 3m\tremaining: 1m 10s\n",
      "1079:\ttotal: 3m 1s\tremaining: 1m 10s\n",
      "1080:\ttotal: 3m 1s\tremaining: 1m 10s\n",
      "1081:\ttotal: 3m 1s\tremaining: 1m 10s\n",
      "1082:\ttotal: 3m 1s\tremaining: 1m 9s\n",
      "1083:\ttotal: 3m 1s\tremaining: 1m 9s\n",
      "1084:\ttotal: 3m 1s\tremaining: 1m 9s\n",
      "1085:\ttotal: 3m 2s\tremaining: 1m 9s\n",
      "1086:\ttotal: 3m 2s\tremaining: 1m 9s\n",
      "1087:\ttotal: 3m 2s\tremaining: 1m 9s\n",
      "1088:\ttotal: 3m 2s\tremaining: 1m 8s\n",
      "1089:\ttotal: 3m 2s\tremaining: 1m 8s\n",
      "1090:\ttotal: 3m 2s\tremaining: 1m 8s\n",
      "1091:\ttotal: 3m 3s\tremaining: 1m 8s\n",
      "1092:\ttotal: 3m 3s\tremaining: 1m 8s\n",
      "1093:\ttotal: 3m 3s\tremaining: 1m 8s\n",
      "1094:\ttotal: 3m 3s\tremaining: 1m 7s\n",
      "1095:\ttotal: 3m 3s\tremaining: 1m 7s\n",
      "1096:\ttotal: 3m 3s\tremaining: 1m 7s\n",
      "1097:\ttotal: 3m 4s\tremaining: 1m 7s\n",
      "1098:\ttotal: 3m 4s\tremaining: 1m 7s\n",
      "1099:\ttotal: 3m 4s\tremaining: 1m 7s\n",
      "1100:\ttotal: 3m 4s\tremaining: 1m 6s\n",
      "1101:\ttotal: 3m 4s\tremaining: 1m 6s\n",
      "1102:\ttotal: 3m 4s\tremaining: 1m 6s\n",
      "1103:\ttotal: 3m 5s\tremaining: 1m 6s\n",
      "1104:\ttotal: 3m 5s\tremaining: 1m 6s\n",
      "1105:\ttotal: 3m 5s\tremaining: 1m 6s\n",
      "1106:\ttotal: 3m 5s\tremaining: 1m 5s\n",
      "1107:\ttotal: 3m 5s\tremaining: 1m 5s\n",
      "1108:\ttotal: 3m 5s\tremaining: 1m 5s\n",
      "1109:\ttotal: 3m 6s\tremaining: 1m 5s\n",
      "1110:\ttotal: 3m 6s\tremaining: 1m 5s\n",
      "1111:\ttotal: 3m 6s\tremaining: 1m 5s\n",
      "1112:\ttotal: 3m 6s\tremaining: 1m 4s\n",
      "1113:\ttotal: 3m 6s\tremaining: 1m 4s\n",
      "1114:\ttotal: 3m 7s\tremaining: 1m 4s\n",
      "1115:\ttotal: 3m 7s\tremaining: 1m 4s\n",
      "1116:\ttotal: 3m 7s\tremaining: 1m 4s\n",
      "1117:\ttotal: 3m 7s\tremaining: 1m 4s\n",
      "1118:\ttotal: 3m 7s\tremaining: 1m 3s\n",
      "1119:\ttotal: 3m 7s\tremaining: 1m 3s\n",
      "1120:\ttotal: 3m 8s\tremaining: 1m 3s\n",
      "1121:\ttotal: 3m 8s\tremaining: 1m 3s\n",
      "1122:\ttotal: 3m 8s\tremaining: 1m 3s\n",
      "1123:\ttotal: 3m 8s\tremaining: 1m 3s\n",
      "1124:\ttotal: 3m 8s\tremaining: 1m 2s\n",
      "1125:\ttotal: 3m 8s\tremaining: 1m 2s\n",
      "1126:\ttotal: 3m 9s\tremaining: 1m 2s\n",
      "1127:\ttotal: 3m 9s\tremaining: 1m 2s\n",
      "1128:\ttotal: 3m 9s\tremaining: 1m 2s\n",
      "1129:\ttotal: 3m 9s\tremaining: 1m 2s\n",
      "1130:\ttotal: 3m 9s\tremaining: 1m 1s\n",
      "1131:\ttotal: 3m 10s\tremaining: 1m 1s\n",
      "1132:\ttotal: 3m 10s\tremaining: 1m 1s\n",
      "1133:\ttotal: 3m 10s\tremaining: 1m 1s\n",
      "1134:\ttotal: 3m 10s\tremaining: 1m 1s\n",
      "1135:\ttotal: 3m 10s\tremaining: 1m 1s\n",
      "1136:\ttotal: 3m 10s\tremaining: 1m\n",
      "1137:\ttotal: 3m 10s\tremaining: 1m\n",
      "1138:\ttotal: 3m 11s\tremaining: 1m\n",
      "1139:\ttotal: 3m 11s\tremaining: 1m\n",
      "1140:\ttotal: 3m 11s\tremaining: 1m\n",
      "1141:\ttotal: 3m 11s\tremaining: 1m\n",
      "1142:\ttotal: 3m 11s\tremaining: 59.9s\n",
      "1143:\ttotal: 3m 12s\tremaining: 59.7s\n",
      "1144:\ttotal: 3m 12s\tremaining: 59.6s\n",
      "1145:\ttotal: 3m 12s\tremaining: 59.4s\n",
      "1146:\ttotal: 3m 12s\tremaining: 59.2s\n",
      "1147:\ttotal: 3m 12s\tremaining: 59.1s\n",
      "1148:\ttotal: 3m 12s\tremaining: 58.9s\n",
      "1149:\ttotal: 3m 13s\tremaining: 58.7s\n",
      "1150:\ttotal: 3m 13s\tremaining: 58.6s\n",
      "1151:\ttotal: 3m 13s\tremaining: 58.4s\n",
      "1152:\ttotal: 3m 13s\tremaining: 58.2s\n",
      "1153:\ttotal: 3m 13s\tremaining: 58.1s\n",
      "1154:\ttotal: 3m 13s\tremaining: 57.9s\n",
      "1155:\ttotal: 3m 14s\tremaining: 57.7s\n",
      "1156:\ttotal: 3m 14s\tremaining: 57.6s\n",
      "1157:\ttotal: 3m 14s\tremaining: 57.4s\n",
      "1158:\ttotal: 3m 14s\tremaining: 57.2s\n",
      "1159:\ttotal: 3m 14s\tremaining: 57.1s\n",
      "1160:\ttotal: 3m 14s\tremaining: 56.9s\n",
      "1161:\ttotal: 3m 15s\tremaining: 56.7s\n",
      "1162:\ttotal: 3m 15s\tremaining: 56.6s\n",
      "1163:\ttotal: 3m 15s\tremaining: 56.4s\n",
      "1164:\ttotal: 3m 15s\tremaining: 56.2s\n",
      "1165:\ttotal: 3m 15s\tremaining: 56.1s\n",
      "1166:\ttotal: 3m 15s\tremaining: 55.9s\n",
      "1167:\ttotal: 3m 16s\tremaining: 55.7s\n",
      "1168:\ttotal: 3m 16s\tremaining: 55.5s\n",
      "1169:\ttotal: 3m 16s\tremaining: 55.4s\n",
      "1170:\ttotal: 3m 16s\tremaining: 55.2s\n",
      "1171:\ttotal: 3m 16s\tremaining: 55s\n",
      "1172:\ttotal: 3m 16s\tremaining: 54.9s\n",
      "1173:\ttotal: 3m 16s\tremaining: 54.7s\n",
      "1174:\ttotal: 3m 17s\tremaining: 54.5s\n",
      "1175:\ttotal: 3m 17s\tremaining: 54.4s\n",
      "1176:\ttotal: 3m 17s\tremaining: 54.2s\n",
      "1177:\ttotal: 3m 17s\tremaining: 54s\n",
      "1178:\ttotal: 3m 17s\tremaining: 53.8s\n",
      "1179:\ttotal: 3m 17s\tremaining: 53.7s\n",
      "1180:\ttotal: 3m 18s\tremaining: 53.5s\n",
      "1181:\ttotal: 3m 18s\tremaining: 53.3s\n",
      "1182:\ttotal: 3m 18s\tremaining: 53.1s\n",
      "1183:\ttotal: 3m 18s\tremaining: 53s\n",
      "1184:\ttotal: 3m 18s\tremaining: 52.8s\n",
      "1185:\ttotal: 3m 18s\tremaining: 52.6s\n",
      "1186:\ttotal: 3m 19s\tremaining: 52.5s\n",
      "1187:\ttotal: 3m 19s\tremaining: 52.3s\n",
      "1188:\ttotal: 3m 19s\tremaining: 52.2s\n",
      "1189:\ttotal: 3m 19s\tremaining: 52s\n",
      "1190:\ttotal: 3m 19s\tremaining: 51.8s\n",
      "1191:\ttotal: 3m 19s\tremaining: 51.7s\n",
      "1192:\ttotal: 3m 20s\tremaining: 51.5s\n",
      "1193:\ttotal: 3m 20s\tremaining: 51.3s\n",
      "1194:\ttotal: 3m 20s\tremaining: 51.1s\n",
      "1195:\ttotal: 3m 20s\tremaining: 51s\n",
      "1196:\ttotal: 3m 20s\tremaining: 50.8s\n",
      "1197:\ttotal: 3m 20s\tremaining: 50.6s\n",
      "1198:\ttotal: 3m 21s\tremaining: 50.5s\n",
      "1199:\ttotal: 3m 21s\tremaining: 50.3s\n",
      "1200:\ttotal: 3m 21s\tremaining: 50.2s\n",
      "1201:\ttotal: 3m 21s\tremaining: 50s\n",
      "1202:\ttotal: 3m 21s\tremaining: 49.8s\n",
      "1203:\ttotal: 3m 21s\tremaining: 49.6s\n",
      "1204:\ttotal: 3m 22s\tremaining: 49.5s\n",
      "1205:\ttotal: 3m 22s\tremaining: 49.3s\n",
      "1206:\ttotal: 3m 22s\tremaining: 49.1s\n",
      "1207:\ttotal: 3m 22s\tremaining: 49s\n",
      "1208:\ttotal: 3m 22s\tremaining: 48.8s\n",
      "1209:\ttotal: 3m 22s\tremaining: 48.6s\n",
      "1210:\ttotal: 3m 23s\tremaining: 48.5s\n",
      "1211:\ttotal: 3m 23s\tremaining: 48.3s\n",
      "1212:\ttotal: 3m 23s\tremaining: 48.1s\n",
      "1213:\ttotal: 3m 23s\tremaining: 48s\n",
      "1214:\ttotal: 3m 23s\tremaining: 47.8s\n",
      "1215:\ttotal: 3m 23s\tremaining: 47.6s\n",
      "1216:\ttotal: 3m 24s\tremaining: 47.5s\n",
      "1217:\ttotal: 3m 24s\tremaining: 47.3s\n",
      "1218:\ttotal: 3m 24s\tremaining: 47.1s\n",
      "1219:\ttotal: 3m 24s\tremaining: 46.9s\n",
      "1220:\ttotal: 3m 24s\tremaining: 46.8s\n",
      "1221:\ttotal: 3m 24s\tremaining: 46.6s\n",
      "1222:\ttotal: 3m 25s\tremaining: 46.5s\n",
      "1223:\ttotal: 3m 25s\tremaining: 46.3s\n",
      "1224:\ttotal: 3m 25s\tremaining: 46.1s\n",
      "1225:\ttotal: 3m 25s\tremaining: 46s\n",
      "1226:\ttotal: 3m 25s\tremaining: 45.8s\n",
      "1227:\ttotal: 3m 25s\tremaining: 45.6s\n",
      "1228:\ttotal: 3m 26s\tremaining: 45.4s\n",
      "1229:\ttotal: 3m 26s\tremaining: 45.3s\n",
      "1230:\ttotal: 3m 26s\tremaining: 45.1s\n",
      "1231:\ttotal: 3m 26s\tremaining: 44.9s\n",
      "1232:\ttotal: 3m 26s\tremaining: 44.8s\n",
      "1233:\ttotal: 3m 26s\tremaining: 44.6s\n",
      "1234:\ttotal: 3m 27s\tremaining: 44.4s\n",
      "1235:\ttotal: 3m 27s\tremaining: 44.3s\n",
      "1236:\ttotal: 3m 27s\tremaining: 44.1s\n",
      "1237:\ttotal: 3m 27s\tremaining: 43.9s\n",
      "1238:\ttotal: 3m 27s\tremaining: 43.8s\n",
      "1239:\ttotal: 3m 27s\tremaining: 43.6s\n",
      "1240:\ttotal: 3m 28s\tremaining: 43.4s\n",
      "1241:\ttotal: 3m 28s\tremaining: 43.3s\n",
      "1242:\ttotal: 3m 28s\tremaining: 43.1s\n",
      "1243:\ttotal: 3m 28s\tremaining: 42.9s\n",
      "1244:\ttotal: 3m 28s\tremaining: 42.8s\n",
      "1245:\ttotal: 3m 28s\tremaining: 42.6s\n",
      "1246:\ttotal: 3m 29s\tremaining: 42.4s\n",
      "1247:\ttotal: 3m 29s\tremaining: 42.3s\n",
      "1248:\ttotal: 3m 29s\tremaining: 42.1s\n",
      "1249:\ttotal: 3m 29s\tremaining: 41.9s\n",
      "1250:\ttotal: 3m 29s\tremaining: 41.8s\n",
      "1251:\ttotal: 3m 30s\tremaining: 41.6s\n",
      "1252:\ttotal: 3m 30s\tremaining: 41.4s\n",
      "1253:\ttotal: 3m 30s\tremaining: 41.3s\n",
      "1254:\ttotal: 3m 30s\tremaining: 41.1s\n",
      "1255:\ttotal: 3m 30s\tremaining: 40.9s\n",
      "1256:\ttotal: 3m 30s\tremaining: 40.8s\n",
      "1257:\ttotal: 3m 30s\tremaining: 40.6s\n",
      "1258:\ttotal: 3m 31s\tremaining: 40.4s\n",
      "1259:\ttotal: 3m 31s\tremaining: 40.3s\n",
      "1260:\ttotal: 3m 31s\tremaining: 40.1s\n",
      "1261:\ttotal: 3m 31s\tremaining: 39.9s\n",
      "1262:\ttotal: 3m 32s\tremaining: 39.8s\n",
      "1263:\ttotal: 3m 32s\tremaining: 39.6s\n",
      "1264:\ttotal: 3m 32s\tremaining: 39.5s\n",
      "1265:\ttotal: 3m 32s\tremaining: 39.3s\n",
      "1266:\ttotal: 3m 32s\tremaining: 39.1s\n",
      "1267:\ttotal: 3m 32s\tremaining: 39s\n",
      "1268:\ttotal: 3m 33s\tremaining: 38.8s\n",
      "1269:\ttotal: 3m 33s\tremaining: 38.6s\n",
      "1270:\ttotal: 3m 33s\tremaining: 38.5s\n",
      "1271:\ttotal: 3m 33s\tremaining: 38.3s\n",
      "1272:\ttotal: 3m 33s\tremaining: 38.1s\n",
      "1273:\ttotal: 3m 34s\tremaining: 38s\n",
      "1274:\ttotal: 3m 34s\tremaining: 37.8s\n",
      "1275:\ttotal: 3m 34s\tremaining: 37.6s\n",
      "1276:\ttotal: 3m 34s\tremaining: 37.5s\n",
      "1277:\ttotal: 3m 34s\tremaining: 37.3s\n",
      "1278:\ttotal: 3m 34s\tremaining: 37.1s\n",
      "1279:\ttotal: 3m 35s\tremaining: 37s\n",
      "1280:\ttotal: 3m 35s\tremaining: 36.8s\n",
      "1281:\ttotal: 3m 35s\tremaining: 36.6s\n",
      "1282:\ttotal: 3m 35s\tremaining: 36.5s\n",
      "1283:\ttotal: 3m 35s\tremaining: 36.3s\n",
      "1284:\ttotal: 3m 35s\tremaining: 36.1s\n",
      "1285:\ttotal: 3m 36s\tremaining: 35.9s\n",
      "1286:\ttotal: 3m 36s\tremaining: 35.8s\n",
      "1287:\ttotal: 3m 36s\tremaining: 35.6s\n",
      "1288:\ttotal: 3m 36s\tremaining: 35.4s\n",
      "1289:\ttotal: 3m 36s\tremaining: 35.3s\n",
      "1290:\ttotal: 3m 36s\tremaining: 35.1s\n",
      "1291:\ttotal: 3m 37s\tremaining: 34.9s\n",
      "1292:\ttotal: 3m 37s\tremaining: 34.8s\n",
      "1293:\ttotal: 3m 37s\tremaining: 34.6s\n",
      "1294:\ttotal: 3m 37s\tremaining: 34.4s\n",
      "1295:\ttotal: 3m 37s\tremaining: 34.3s\n",
      "1296:\ttotal: 3m 37s\tremaining: 34.1s\n",
      "1297:\ttotal: 3m 38s\tremaining: 33.9s\n",
      "1298:\ttotal: 3m 38s\tremaining: 33.8s\n",
      "1299:\ttotal: 3m 38s\tremaining: 33.6s\n",
      "1300:\ttotal: 3m 38s\tremaining: 33.4s\n",
      "1301:\ttotal: 3m 38s\tremaining: 33.3s\n",
      "1302:\ttotal: 3m 38s\tremaining: 33.1s\n",
      "1303:\ttotal: 3m 39s\tremaining: 32.9s\n",
      "1304:\ttotal: 3m 39s\tremaining: 32.8s\n",
      "1305:\ttotal: 3m 39s\tremaining: 32.6s\n",
      "1306:\ttotal: 3m 39s\tremaining: 32.4s\n",
      "1307:\ttotal: 3m 39s\tremaining: 32.3s\n",
      "1308:\ttotal: 3m 40s\tremaining: 32.1s\n",
      "1309:\ttotal: 3m 40s\tremaining: 31.9s\n",
      "1310:\ttotal: 3m 40s\tremaining: 31.8s\n",
      "1311:\ttotal: 3m 40s\tremaining: 31.6s\n",
      "1312:\ttotal: 3m 40s\tremaining: 31.5s\n",
      "1313:\ttotal: 3m 41s\tremaining: 31.3s\n",
      "1314:\ttotal: 3m 41s\tremaining: 31.1s\n",
      "1315:\ttotal: 3m 41s\tremaining: 31s\n",
      "1316:\ttotal: 3m 41s\tremaining: 30.8s\n",
      "1317:\ttotal: 3m 41s\tremaining: 30.6s\n",
      "1318:\ttotal: 3m 41s\tremaining: 30.5s\n",
      "1319:\ttotal: 3m 42s\tremaining: 30.3s\n",
      "1320:\ttotal: 3m 42s\tremaining: 30.1s\n",
      "1321:\ttotal: 3m 42s\tremaining: 30s\n",
      "1322:\ttotal: 3m 42s\tremaining: 29.8s\n",
      "1323:\ttotal: 3m 42s\tremaining: 29.6s\n",
      "1324:\ttotal: 3m 43s\tremaining: 29.5s\n",
      "1325:\ttotal: 3m 43s\tremaining: 29.3s\n",
      "1326:\ttotal: 3m 43s\tremaining: 29.1s\n",
      "1327:\ttotal: 3m 43s\tremaining: 29s\n",
      "1328:\ttotal: 3m 43s\tremaining: 28.8s\n",
      "1329:\ttotal: 3m 44s\tremaining: 28.6s\n",
      "1330:\ttotal: 3m 44s\tremaining: 28.5s\n",
      "1331:\ttotal: 3m 44s\tremaining: 28.3s\n",
      "1332:\ttotal: 3m 44s\tremaining: 28.1s\n",
      "1333:\ttotal: 3m 44s\tremaining: 28s\n",
      "1334:\ttotal: 3m 44s\tremaining: 27.8s\n",
      "1335:\ttotal: 3m 45s\tremaining: 27.6s\n",
      "1336:\ttotal: 3m 45s\tremaining: 27.5s\n",
      "1337:\ttotal: 3m 45s\tremaining: 27.3s\n",
      "1338:\ttotal: 3m 45s\tremaining: 27.1s\n",
      "1339:\ttotal: 3m 45s\tremaining: 27s\n",
      "1340:\ttotal: 3m 46s\tremaining: 26.8s\n",
      "1341:\ttotal: 3m 46s\tremaining: 26.6s\n",
      "1342:\ttotal: 3m 46s\tremaining: 26.5s\n",
      "1343:\ttotal: 3m 46s\tremaining: 26.3s\n",
      "1344:\ttotal: 3m 46s\tremaining: 26.1s\n",
      "1345:\ttotal: 3m 46s\tremaining: 26s\n",
      "1346:\ttotal: 3m 47s\tremaining: 25.8s\n",
      "1347:\ttotal: 3m 47s\tremaining: 25.6s\n",
      "1348:\ttotal: 3m 47s\tremaining: 25.5s\n",
      "1349:\ttotal: 3m 47s\tremaining: 25.3s\n",
      "1350:\ttotal: 3m 47s\tremaining: 25.1s\n",
      "1351:\ttotal: 3m 47s\tremaining: 25s\n",
      "1352:\ttotal: 3m 48s\tremaining: 24.8s\n",
      "1353:\ttotal: 3m 48s\tremaining: 24.6s\n",
      "1354:\ttotal: 3m 48s\tremaining: 24.4s\n",
      "1355:\ttotal: 3m 48s\tremaining: 24.3s\n",
      "1356:\ttotal: 3m 48s\tremaining: 24.1s\n",
      "1357:\ttotal: 3m 49s\tremaining: 23.9s\n",
      "1358:\ttotal: 3m 49s\tremaining: 23.8s\n",
      "1359:\ttotal: 3m 49s\tremaining: 23.6s\n",
      "1360:\ttotal: 3m 49s\tremaining: 23.4s\n",
      "1361:\ttotal: 3m 49s\tremaining: 23.3s\n",
      "1362:\ttotal: 3m 49s\tremaining: 23.1s\n",
      "1363:\ttotal: 3m 50s\tremaining: 22.9s\n",
      "1364:\ttotal: 3m 50s\tremaining: 22.8s\n",
      "1365:\ttotal: 3m 50s\tremaining: 22.6s\n",
      "1366:\ttotal: 3m 50s\tremaining: 22.4s\n",
      "1367:\ttotal: 3m 50s\tremaining: 22.3s\n",
      "1368:\ttotal: 3m 51s\tremaining: 22.1s\n",
      "1369:\ttotal: 3m 51s\tremaining: 21.9s\n",
      "1370:\ttotal: 3m 51s\tremaining: 21.8s\n",
      "1371:\ttotal: 3m 51s\tremaining: 21.6s\n",
      "1372:\ttotal: 3m 51s\tremaining: 21.4s\n",
      "1373:\ttotal: 3m 52s\tremaining: 21.3s\n",
      "1374:\ttotal: 3m 52s\tremaining: 21.1s\n",
      "1375:\ttotal: 3m 52s\tremaining: 20.9s\n",
      "1376:\ttotal: 3m 52s\tremaining: 20.8s\n",
      "1377:\ttotal: 3m 52s\tremaining: 20.6s\n",
      "1378:\ttotal: 3m 52s\tremaining: 20.4s\n",
      "1379:\ttotal: 3m 53s\tremaining: 20.3s\n",
      "1380:\ttotal: 3m 53s\tremaining: 20.1s\n",
      "1381:\ttotal: 3m 53s\tremaining: 19.9s\n",
      "1382:\ttotal: 3m 53s\tremaining: 19.8s\n",
      "1383:\ttotal: 3m 53s\tremaining: 19.6s\n",
      "1384:\ttotal: 3m 53s\tremaining: 19.4s\n",
      "1385:\ttotal: 3m 54s\tremaining: 19.3s\n",
      "1386:\ttotal: 3m 54s\tremaining: 19.1s\n",
      "1387:\ttotal: 3m 54s\tremaining: 18.9s\n",
      "1388:\ttotal: 3m 54s\tremaining: 18.8s\n",
      "1389:\ttotal: 3m 54s\tremaining: 18.6s\n",
      "1390:\ttotal: 3m 55s\tremaining: 18.4s\n",
      "1391:\ttotal: 3m 55s\tremaining: 18.3s\n",
      "1392:\ttotal: 3m 55s\tremaining: 18.1s\n",
      "1393:\ttotal: 3m 55s\tremaining: 17.9s\n",
      "1394:\ttotal: 3m 55s\tremaining: 17.7s\n",
      "1395:\ttotal: 3m 55s\tremaining: 17.6s\n",
      "1396:\ttotal: 3m 56s\tremaining: 17.4s\n",
      "1397:\ttotal: 3m 56s\tremaining: 17.2s\n",
      "1398:\ttotal: 3m 56s\tremaining: 17.1s\n",
      "1399:\ttotal: 3m 56s\tremaining: 16.9s\n",
      "1400:\ttotal: 3m 56s\tremaining: 16.7s\n",
      "1401:\ttotal: 3m 56s\tremaining: 16.6s\n",
      "1402:\ttotal: 3m 57s\tremaining: 16.4s\n",
      "1403:\ttotal: 3m 57s\tremaining: 16.2s\n",
      "1404:\ttotal: 3m 57s\tremaining: 16s\n",
      "1405:\ttotal: 3m 57s\tremaining: 15.9s\n",
      "1406:\ttotal: 3m 57s\tremaining: 15.7s\n",
      "1407:\ttotal: 3m 57s\tremaining: 15.5s\n",
      "1408:\ttotal: 3m 58s\tremaining: 15.4s\n",
      "1409:\ttotal: 3m 58s\tremaining: 15.2s\n",
      "1410:\ttotal: 3m 58s\tremaining: 15s\n",
      "1411:\ttotal: 3m 58s\tremaining: 14.9s\n",
      "1412:\ttotal: 3m 58s\tremaining: 14.7s\n",
      "1413:\ttotal: 3m 59s\tremaining: 14.5s\n",
      "1414:\ttotal: 3m 59s\tremaining: 14.4s\n",
      "1415:\ttotal: 3m 59s\tremaining: 14.2s\n",
      "1416:\ttotal: 3m 59s\tremaining: 14s\n",
      "1417:\ttotal: 3m 59s\tremaining: 13.9s\n",
      "1418:\ttotal: 3m 59s\tremaining: 13.7s\n",
      "1419:\ttotal: 4m\tremaining: 13.5s\n",
      "1420:\ttotal: 4m\tremaining: 13.4s\n",
      "1421:\ttotal: 4m\tremaining: 13.2s\n",
      "1422:\ttotal: 4m\tremaining: 13s\n",
      "1423:\ttotal: 4m\tremaining: 12.9s\n",
      "1424:\ttotal: 4m 1s\tremaining: 12.7s\n",
      "1425:\ttotal: 4m 1s\tremaining: 12.5s\n",
      "1426:\ttotal: 4m 1s\tremaining: 12.3s\n",
      "1427:\ttotal: 4m 1s\tremaining: 12.2s\n",
      "1428:\ttotal: 4m 1s\tremaining: 12s\n",
      "1429:\ttotal: 4m 1s\tremaining: 11.8s\n",
      "1430:\ttotal: 4m 1s\tremaining: 11.7s\n",
      "1431:\ttotal: 4m 2s\tremaining: 11.5s\n",
      "1432:\ttotal: 4m 2s\tremaining: 11.3s\n",
      "1433:\ttotal: 4m 2s\tremaining: 11.2s\n",
      "1434:\ttotal: 4m 2s\tremaining: 11s\n",
      "1435:\ttotal: 4m 2s\tremaining: 10.8s\n",
      "1436:\ttotal: 4m 2s\tremaining: 10.6s\n",
      "1437:\ttotal: 4m 3s\tremaining: 10.5s\n",
      "1438:\ttotal: 4m 3s\tremaining: 10.3s\n",
      "1439:\ttotal: 4m 3s\tremaining: 10.1s\n",
      "1440:\ttotal: 4m 3s\tremaining: 9.97s\n",
      "1441:\ttotal: 4m 3s\tremaining: 9.8s\n",
      "1442:\ttotal: 4m 3s\tremaining: 9.63s\n",
      "1443:\ttotal: 4m 4s\tremaining: 9.46s\n",
      "1444:\ttotal: 4m 4s\tremaining: 9.29s\n",
      "1445:\ttotal: 4m 4s\tremaining: 9.12s\n",
      "1446:\ttotal: 4m 4s\tremaining: 8.95s\n",
      "1447:\ttotal: 4m 4s\tremaining: 8.79s\n",
      "1448:\ttotal: 4m 4s\tremaining: 8.62s\n",
      "1449:\ttotal: 4m 4s\tremaining: 8.45s\n",
      "1450:\ttotal: 4m 5s\tremaining: 8.28s\n",
      "1451:\ttotal: 4m 5s\tremaining: 8.11s\n",
      "1452:\ttotal: 4m 5s\tremaining: 7.94s\n",
      "1453:\ttotal: 4m 5s\tremaining: 7.77s\n",
      "1454:\ttotal: 4m 5s\tremaining: 7.6s\n",
      "1455:\ttotal: 4m 5s\tremaining: 7.43s\n",
      "1456:\ttotal: 4m 6s\tremaining: 7.26s\n",
      "1457:\ttotal: 4m 6s\tremaining: 7.09s\n",
      "1458:\ttotal: 4m 6s\tremaining: 6.92s\n",
      "1459:\ttotal: 4m 6s\tremaining: 6.75s\n",
      "1460:\ttotal: 4m 6s\tremaining: 6.59s\n",
      "1461:\ttotal: 4m 6s\tremaining: 6.42s\n",
      "1462:\ttotal: 4m 7s\tremaining: 6.25s\n",
      "1463:\ttotal: 4m 7s\tremaining: 6.08s\n",
      "1464:\ttotal: 4m 7s\tremaining: 5.91s\n",
      "1465:\ttotal: 4m 7s\tremaining: 5.74s\n",
      "1466:\ttotal: 4m 7s\tremaining: 5.57s\n",
      "1467:\ttotal: 4m 7s\tremaining: 5.4s\n",
      "1468:\ttotal: 4m 8s\tremaining: 5.24s\n",
      "1469:\ttotal: 4m 8s\tremaining: 5.07s\n",
      "1470:\ttotal: 4m 8s\tremaining: 4.9s\n",
      "1471:\ttotal: 4m 8s\tremaining: 4.73s\n",
      "1472:\ttotal: 4m 8s\tremaining: 4.56s\n",
      "1473:\ttotal: 4m 8s\tremaining: 4.39s\n",
      "1474:\ttotal: 4m 9s\tremaining: 4.22s\n",
      "1475:\ttotal: 4m 9s\tremaining: 4.05s\n",
      "1476:\ttotal: 4m 9s\tremaining: 3.88s\n",
      "1477:\ttotal: 4m 9s\tremaining: 3.71s\n",
      "1478:\ttotal: 4m 9s\tremaining: 3.55s\n",
      "1479:\ttotal: 4m 9s\tremaining: 3.38s\n",
      "1480:\ttotal: 4m 10s\tremaining: 3.21s\n",
      "1481:\ttotal: 4m 10s\tremaining: 3.04s\n",
      "1482:\ttotal: 4m 10s\tremaining: 2.87s\n",
      "1483:\ttotal: 4m 10s\tremaining: 2.7s\n",
      "1484:\ttotal: 4m 10s\tremaining: 2.53s\n",
      "1485:\ttotal: 4m 10s\tremaining: 2.36s\n",
      "1486:\ttotal: 4m 11s\tremaining: 2.19s\n",
      "1487:\ttotal: 4m 11s\tremaining: 2.03s\n",
      "1488:\ttotal: 4m 11s\tremaining: 1.86s\n",
      "1489:\ttotal: 4m 11s\tremaining: 1.69s\n",
      "1490:\ttotal: 4m 11s\tremaining: 1.52s\n",
      "1491:\ttotal: 4m 11s\tremaining: 1.35s\n",
      "1492:\ttotal: 4m 11s\tremaining: 1.18s\n",
      "1493:\ttotal: 4m 12s\tremaining: 1.01s\n",
      "1494:\ttotal: 4m 12s\tremaining: 844ms\n",
      "1495:\ttotal: 4m 12s\tremaining: 675ms\n",
      "1496:\ttotal: 4m 12s\tremaining: 506ms\n",
      "1497:\ttotal: 4m 12s\tremaining: 337ms\n",
      "1498:\ttotal: 4m 12s\tremaining: 169ms\n",
      "1499:\ttotal: 4m 13s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x214fe1a19f0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hyperparameter tuning\n",
    "\n",
    "from hyperopt import fmin, tpe, hp, Trials, STATUS_OK\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "\n",
    "long_df = pd.read_csv(\"long_df.csv\")\n",
    "# Prepare data (reuse your existing preprocessing)\n",
    "\n",
    "extra_cols = [\"winner_id\",\"loser_id\"]\n",
    "\n",
    "feature_cols = ['age_diff','ft_diff','elo_diff_pre','surface','winner_hand','loser_hand']\n",
    "\n",
    "cat_features = ['surface','winner_hand','loser_hand']\n",
    "\n",
    "X = long_df[feature_cols].copy()\n",
    "y = long_df['label'].copy()\n",
    "\n",
    "# Handle categorical NaNs (same as in your fit method)\n",
    "for col in cat_features:\n",
    "    X[col] = X[col].fillna('missing').astype(str)\n",
    "\n",
    "# Split into train/validation (keep test set untouched)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "train_pool = Pool(X_train, y_train, cat_features=cat_features)\n",
    "val_pool = Pool(X_val, y_val, cat_features=cat_features)\n",
    "\n",
    "# Define search space\n",
    "space = {\n",
    "    'depth': hp.quniform('depth', 4, 8, 1),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.3)),\n",
    "    'l2_leaf_reg': hp.loguniform('l2_leaf_reg', np.log(1), np.log(50)),\n",
    "    'bootstrap_type': hp.choice('bootstrap_type', ['Bayesian', 'Bernoulli']),\n",
    "    'bagging_temperature': hp.uniform('bagging_temperature', 0.01, 1.0),\n",
    "    'subsample': hp.pchoice('subsample_choice', [\n",
    "        (0.5, None),  # 50% chance to ignore subsample\n",
    "        (0.5, hp.uniform('subsample', 0.5, 1.0))\n",
    "    ]),\n",
    "    'min_data_in_leaf': hp.quniform('min_data_in_leaf', 10, 100, 5),\n",
    "    'random_strength': hp.quniform('random_strength', 1, 3, 0.1),\n",
    "    'iterations': hp.quniform('iterations', 800, 2000, 100),\n",
    "}\n",
    "\n",
    "def objective(params):\n",
    "    # Convert parameters\n",
    "    params = {\n",
    "        'depth': int(params['depth']),\n",
    "        'learning_rate': params['learning_rate'],\n",
    "        'l2_leaf_reg': params['l2_leaf_reg'],\n",
    "        'bootstrap_type': params['bootstrap_type'],\n",
    "        'bagging_temperature': (params['bagging_temperature'] \n",
    "                               if params['bootstrap_type'] == 'Bayesian' \n",
    "                               else None),\n",
    "        'subsample': (params['subsample'] \n",
    "                     if params['bootstrap_type'] == 'Bernoulli' \n",
    "                     else None),\n",
    "        'min_data_in_leaf': int(params['min_data_in_leaf']),\n",
    "        'random_strength': params['random_strength'],\n",
    "        'iterations': int(params['iterations']),\n",
    "        'eval_metric': 'AUC',\n",
    "        'early_stopping_rounds': 50,\n",
    "        'random_seed': 42,\n",
    "        'verbose': False,\n",
    "        'task_type': 'GPU'  # Remove if not using GPU\n",
    "    }\n",
    "    \n",
    "    # Clean up None values\n",
    "    params = {k: v for k, v in params.items() if v is not None}\n",
    "    \n",
    "    model = CatBoostClassifier(**params)\n",
    "    model.fit(train_pool, eval_set=val_pool)\n",
    "    \n",
    "    val_pred = model.predict_proba(val_pool)[:, 1]\n",
    "    auc = roc_auc_score(y_val, val_pred)\n",
    "    \n",
    "    return {'loss': -auc, 'status': STATUS_OK, 'model': model}\n",
    "# Run optimization\n",
    "trials = Trials()\n",
    "best = fmin(\n",
    "    fn=objective,\n",
    "    space=space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=50,  # Increase for better results\n",
    "    trials=trials,\n",
    "    rstate=np.random.default_rng(42)\n",
    ")\n",
    "\n",
    "# Get best parameters\n",
    "best_params = {\n",
    "    'depth': int(best['depth']),\n",
    "    'learning_rate': best['learning_rate'],\n",
    "    'l2_leaf_reg': best['l2_leaf_reg'],\n",
    "    'bagging_temperature': best['bagging_temperature'],\n",
    "    'subsample': best['subsample'],\n",
    "    'min_data_in_leaf': int(best['min_data_in_leaf']),\n",
    "    'random_strength': best['random_strength'],\n",
    "    'iterations': int(best['iterations']),\n",
    "    'eval_metric': 'AUC',\n",
    "    'early_stopping_rounds': 50,\n",
    "    'random_seed': 42\n",
    "}\n",
    "\n",
    "print(\"Best parameters:\")\n",
    "print(best_params)\n",
    "\n",
    "# Retrain with best params on full training data\n",
    "final_model = CatBoostClassifier(**best_params)\n",
    "final_model.fit(Pool(X, y, cat_features=cat_features))\n",
    "\n",
    "# Evaluate on test set (make sure you have held-out test data)\n",
    "# test_metrics = predictor.evaluate(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dde07c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.save_model(\"trained_model.cbm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5425c6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report\n",
    "\n",
    "# After training (predictor.fit(long_df)), evaluate on full dataset\n",
    "full_dataset_metrics = predictor.evaluate(long_df)\n",
    "\n",
    "# Evaluate on specific tournament (example)\n",
    "wimbledon_data = long_df\n",
    "wimbledon_metrics = predictor.evaluate(wimbledon_data)\n",
    "\n",
    "# Get metrics programmatically\n",
    "print(f\"Overall AUC: {full_dataset_metrics['auc']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aabdcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def predict_winner_probability(\n",
    "    fname_p1: str,\n",
    "    lname_p1: str,\n",
    "    fname_p2: str,\n",
    "    lname_p2: str ,\n",
    "    surface: str,\n",
    "    atp_players: pd.DataFrame,\n",
    "    atp_matches: pd.DataFrame,\n",
    "    model\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Predicts the probability of `player1` winning against `player2` using the CatBoost model.\n",
    "    \n",
    "    Args:\n",
    "        player1: Full name of player 1 (e.g., \"Rafael Nadal\")\n",
    "        player2: Full name of player 2 (e.g., \"Novak Djokovic\")\n",
    "        surface: Match surface ('Hard', 'Clay', 'Grass')\n",
    "        round_level: Tournament round ('F', 'SF', 'QF', etc.)\n",
    "        atp_players: DataFrame with columns ['player_id', 'name_first', 'name_last', 'dob', 'hand', 'height']\n",
    "        atp_matches: DataFrame containing historical match data\n",
    "        model_path: Path to the trained CatBoost model\n",
    "    \n",
    "    Returns:\n",
    "        Probability of player1 winning (between 0 and 1)\n",
    "    \"\"\"\n",
    "   # Function to get player ID from first and last name\n",
    "    def get_player_id(first_name, last_name, df):\n",
    "        player_row = df[(df['name_first'] == first_name) & (df['name_last'] == last_name)]\n",
    "        \n",
    "        if player_row.empty:\n",
    "            raise ValueError(f\"Player '{first_name} {last_name}' not found.\")\n",
    "        return player_row.iloc[0]\n",
    "    \n",
    "    try:\n",
    "        # Split input names into first and last\n",
    "\n",
    "        \n",
    "        # Retrieve player IDs\n",
    "        p1 = get_player_id(fname_p1.strip(), lname_p1.strip(), atp_players)\n",
    "        p2 = get_player_id(fname_p2.strip(), lname_p2.strip(), atp_players)\n",
    "    except ValueError as e:\n",
    "        print(e)\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Calculate age diff\n",
    "    today = pd.Timestamp('today')\n",
    "    age_p1 = today.year - pd.to_datetime(p1['dob']).year\n",
    "    age_p2 = today.year - pd.to_datetime(p2['dob']).year\n",
    "    age_diff = age_p1 - age_p2\n",
    "    \n",
    "     # Height difference\n",
    "    ht_diff = p1['height'] - p2['height']\n",
    "\n",
    "    # Get latest Elo ratings \n",
    "    def get_latest_elo(player_id: int, df: pd.DataFrame) -> float:\n",
    "        # Check if player was a winner or loser in their latest match\n",
    "        winner_matches = df[df['winner_id'] == player_id]\n",
    "        loser_matches = df[df['loser_id'] == player_id]\n",
    "        \n",
    "        if not winner_matches.empty:\n",
    "            return winner_matches.iloc[-1]['winner_elo_post']\n",
    "        elif not loser_matches.empty:\n",
    "            return loser_matches.iloc[-1]['loser_elo_post']\n",
    "        else:\n",
    "            return 1500  # Initial rating\n",
    "    \n",
    "    elo_p1 = get_latest_elo(p1['player_id'], atp_matches)\n",
    "    elo_p2 = get_latest_elo(p2['player_id'], atp_matches)\n",
    "    elo_diff = elo_p1 - elo_p2\n",
    "\n",
    "    # Create feature vector (assumes player1 is hypothetical winner)\n",
    "    features = pd.DataFrame([{\n",
    "        'rank_diff': 0,  # Placeholder (requires ranking data)\n",
    "        'age_diff': age_diff,\n",
    "        'ft_diff': ht_diff,\n",
    "        'server_advantage': 0,  # Placeholder\n",
    "        'bp_effectiveness': 0,  # Placeholder\n",
    "        'total_points_played': 0,  # Placeholder\n",
    "        'match_efficiency': 0,  # Placeholder\n",
    "        'elo_diff_pre': elo_diff,\n",
    "        'surface': surface.lower(),\n",
    "        'winner_hand': p1['hand'].lower(),\n",
    "        'loser_hand': p2['hand'].lower()\n",
    "    }])\n",
    "    \n",
    "     # Create a Pool with categorical features\n",
    "    prediction_pool = Pool(\n",
    "        data=features,\n",
    "        cat_features=['surface', 'winner_hand', 'loser_hand']\n",
    "    )\n",
    "    \n",
    "    prob = model.predict_proba(prediction_pool)\n",
    "    return prob\n",
    "\n",
    "# Replace 'your_file.csv' with the path to your CSV file\n",
    "player_info = pd.read_csv('data\\\\tennis_atp\\\\atp_players.csv')\n",
    "\n",
    "\n",
    "\n",
    "fname_p1 = \"Jannik \"\n",
    "lname_p1 = \"Sinner\"\n",
    "fname_p2 = \"Alexander\"\n",
    "lname_p2 = \"Zverev\"\n",
    "\n",
    "\n",
    "# Predict probability\n",
    "prob = predict_winner_probability(\n",
    "    fname_p1=fname_p1, \n",
    "    lname_p1=lname_p1,\n",
    "    fname_p2=fname_p2,\n",
    "    lname_p2=lname_p2,\n",
    "    surface=\"hard\",\n",
    "    atp_players=player_info,\n",
    "    atp_matches=df,\n",
    "    model = predictor.model\n",
    ")\n",
    "\n",
    "print(f\"Probability of {fname_p1} {lname_p1} winning: {prob[0][1]}\")\n",
    "print(f\"Probability of {fname_p2} {lname_p2} winning: {prob[0][0]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d895a3f1",
   "metadata": {},
   "source": [
    "### Evaluate Model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sport_predictor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
